{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rPy7CQcNbTkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### added section for training the whole dataset\n",
        "import csv\n",
        "import numpy as np\n",
        "\n",
        "#to read English codes\n",
        "\n",
        "file_nameE = 'English_Encoded'\n",
        "with open(file_nameE+'.csv', 'r') as f:\n",
        "  reader = csv.reader(f)\n",
        "  codes = list(reader)\n",
        "\n",
        "#print(codes)\n",
        "Ecodes = []\n",
        "for row in codes:\n",
        "    nwrow = []\n",
        "    for r in row:\n",
        "        nwrow.append(eval(r))\n",
        "    Ecodes.append(nwrow)\n",
        "#print(Ecodes)\n",
        "\n",
        "# to read Persian codes\n",
        "\n",
        "file_nameP = 'Persian_Encoded'\n",
        "with open(file_nameP+'.csv', 'r') as f:\n",
        "  reader = csv.reader(f)\n",
        "  codes = list(reader)\n",
        "\n",
        "#print(codes)\n",
        "Pcodes = []\n",
        "for row in codes:\n",
        "    nwrow = []\n",
        "    for r in row:\n",
        "        nwrow.append(eval(r))\n",
        "    Pcodes.append(nwrow)\n",
        "print(Pcodes)"
      ],
      "metadata": {
        "id": "9DATlOQ9bM0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### added section for training the whole dataset- padding codes\n",
        "!pip install keras_preprocessing\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "# pad sequence\n",
        "\n",
        "# English\n",
        "padded_Ecodes = pad_sequences(Ecodes, padding='post', dtype = 'float32')\n",
        "padded_EcodesP = padded_Ecodes\n",
        "padded_EcodesP = padded_EcodesP.reshape(42, 3, 21)\n",
        "padded_EcodesP = np.pad(padded_EcodesP, ((0, 0), (0, 1),(0, 3)))\n",
        "padded_Ecodes = padded_EcodesP.reshape(42, 4, 24, 1)\n",
        "\n",
        "### Persian\n",
        "padded_Pcodes = pad_sequences(Pcodes, padding='post', dtype = 'float32')\n",
        "padded_Pcodes = padded_Pcodes.reshape(42, 4, 24, 1)\n",
        "print(padded_EcodesP[0][0])"
      ],
      "metadata": {
        "id": "seaE54yWbuXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### First model ####\n",
        "\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "batch_size = 42\n",
        "epochs = 50\n",
        "timesteps = 4\n",
        "\n",
        "inputs_1_mae = tf.keras.layers.Input(batch_shape=(batch_size, timesteps, 24))\n",
        "lstm_1_mae = tf.keras.layers.LSTM(100, activation='tanh', stateful = True, return_sequences = True)(inputs_1_mae)\n",
        "lstm_2_mae = tf.keras.layers.LSTM(100, activation='relu', stateful = True, return_sequences = True)(lstm_1_mae)\n",
        "output_1_mae = tf.keras.layers.Dense (units = 24)(lstm_2_mae)\n",
        "regressor_mae = tf.keras.Model(inputs= inputs_1_mae, outputs = output_1_mae)\n",
        "#optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy', f1_score, precision, recall]\n",
        "regressor_mae.compile (optimizer = \"SGD\", loss = \"mse\")\n",
        "#regressor_mae.compile (optimizer = \"rmsprop\", loss='sparse_categorical_crossentropy')\n",
        "#regressor_mae.compile (optimizer = \"adam\", loss = 'categorical_crossentropy')\n",
        "\n",
        "regressor_mae.summary()\n",
        "#regressor_mae.fit(padded_Ecodes, padded_Pcodes, epochs=50)\n",
        "history = regressor_mae.fit(padded_Ecodes, padded_Pcodes, epochs=1000, batch_size = 42)\n",
        "score = regressor_mae.evaluate(padded_Ecodes, padded_Pcodes, batch_size=42, verbose=0)\n",
        "#score = regressor_mae.evaluate(padded_Ecodes, padded_Pcodes, verbose=0)\n",
        "\n",
        "print(' Train loss:', score)\n",
        "#plt.plot(history.history['loss'])\n",
        "#plt.show()\n",
        "pd.DataFrame(history.history).plot()\n",
        "plt.title(\"Validation Loss\")\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XXJxQ4MRb0_H",
        "outputId": "c744995f-f83c-4c92-c1ce-bcfc6e381034"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(42, 4, 24)]             0         \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (42, 4, 100)              50000     \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (42, 4, 100)              80400     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (42, 4, 24)               2424      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 132,824\n",
            "Trainable params: 132,824\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/1000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 3.1197\n",
            "Epoch 2/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.0864\n",
            "Epoch 3/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 3.0667\n",
            "Epoch 4/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 3.0512\n",
            "Epoch 5/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3.0371\n",
            "Epoch 6/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3.0241\n",
            "Epoch 7/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 3.0117\n",
            "Epoch 8/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.9996\n",
            "Epoch 9/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.9878\n",
            "Epoch 10/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.9766\n",
            "Epoch 11/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.9655\n",
            "Epoch 12/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.9545\n",
            "Epoch 13/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.9435\n",
            "Epoch 14/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.9326\n",
            "Epoch 15/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.9217\n",
            "Epoch 16/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.9108\n",
            "Epoch 17/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.8999\n",
            "Epoch 18/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.8889\n",
            "Epoch 19/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.8780\n",
            "Epoch 20/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.8670\n",
            "Epoch 21/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.8560\n",
            "Epoch 22/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.8450\n",
            "Epoch 23/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.8341\n",
            "Epoch 24/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.8230\n",
            "Epoch 25/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.8119\n",
            "Epoch 26/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.8007\n",
            "Epoch 27/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.7894\n",
            "Epoch 28/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.7781\n",
            "Epoch 29/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.7668\n",
            "Epoch 30/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.7553\n",
            "Epoch 31/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.7437\n",
            "Epoch 32/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.7321\n",
            "Epoch 33/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.7203\n",
            "Epoch 34/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.7084\n",
            "Epoch 35/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.6964\n",
            "Epoch 36/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.6843\n",
            "Epoch 37/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.6720\n",
            "Epoch 38/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.6596\n",
            "Epoch 39/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.6470\n",
            "Epoch 40/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.6341\n",
            "Epoch 41/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.6211\n",
            "Epoch 42/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.6079\n",
            "Epoch 43/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.5946\n",
            "Epoch 44/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.5810\n",
            "Epoch 45/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.5673\n",
            "Epoch 46/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.5533\n",
            "Epoch 47/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.5391\n",
            "Epoch 48/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.5245\n",
            "Epoch 49/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.5097\n",
            "Epoch 50/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.4946\n",
            "Epoch 51/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.4792\n",
            "Epoch 52/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.4634\n",
            "Epoch 53/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.4472\n",
            "Epoch 54/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.4308\n",
            "Epoch 55/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.4139\n",
            "Epoch 56/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.3967\n",
            "Epoch 57/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.3790\n",
            "Epoch 58/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.3610\n",
            "Epoch 59/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.3424\n",
            "Epoch 60/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.3234\n",
            "Epoch 61/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.3040\n",
            "Epoch 62/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.2841\n",
            "Epoch 63/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.2638\n",
            "Epoch 64/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.2429\n",
            "Epoch 65/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.2215\n",
            "Epoch 66/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.1995\n",
            "Epoch 67/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.1768\n",
            "Epoch 68/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.1535\n",
            "Epoch 69/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.1296\n",
            "Epoch 70/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.1051\n",
            "Epoch 71/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.0799\n",
            "Epoch 72/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.0540\n",
            "Epoch 73/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.0275\n",
            "Epoch 74/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.0004\n",
            "Epoch 75/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.9728\n",
            "Epoch 76/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.9447\n",
            "Epoch 77/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.9162\n",
            "Epoch 78/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.8877\n",
            "Epoch 79/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.8594\n",
            "Epoch 80/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.8318\n",
            "Epoch 81/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.8059\n",
            "Epoch 82/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.7826\n",
            "Epoch 83/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.7632\n",
            "Epoch 84/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.7499\n",
            "Epoch 85/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.7443\n",
            "Epoch 86/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.7482\n",
            "Epoch 87/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.7606\n",
            "Epoch 88/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.7769\n",
            "Epoch 89/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.7896\n",
            "Epoch 90/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.7890\n",
            "Epoch 91/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.7724\n",
            "Epoch 92/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.7454\n",
            "Epoch 93/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.7177\n",
            "Epoch 94/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.6945\n",
            "Epoch 95/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.6774\n",
            "Epoch 96/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.6660\n",
            "Epoch 97/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.6593\n",
            "Epoch 98/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.6578\n",
            "Epoch 99/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.6616\n",
            "Epoch 100/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.6715\n",
            "Epoch 101/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.6857\n",
            "Epoch 102/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.7006\n",
            "Epoch 103/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.7100\n",
            "Epoch 104/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.7099\n",
            "Epoch 105/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.7006\n",
            "Epoch 106/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.6859\n",
            "Epoch 107/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.6714\n",
            "Epoch 108/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.6601\n",
            "Epoch 109/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.6530\n",
            "Epoch 110/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.6507\n",
            "Epoch 111/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.6528\n",
            "Epoch 112/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.6588\n",
            "Epoch 113/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.6663\n",
            "Epoch 114/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.6720\n",
            "Epoch 115/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.6731\n",
            "Epoch 116/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.6694\n",
            "Epoch 117/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.6629\n",
            "Epoch 118/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.6558\n",
            "Epoch 119/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.6499\n",
            "Epoch 120/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.6453\n",
            "Epoch 121/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.6422\n",
            "Epoch 122/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.6390\n",
            "Epoch 123/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.6351\n",
            "Epoch 124/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.6300\n",
            "Epoch 125/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.6244\n",
            "Epoch 126/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.6175\n",
            "Epoch 127/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.6156\n",
            "Epoch 128/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.9754\n",
            "Epoch 129/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 10.6137\n",
            "Epoch 130/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.2045\n",
            "Epoch 131/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.1626\n",
            "Epoch 132/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.0826\n",
            "Epoch 133/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.0837\n",
            "Epoch 134/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.0945\n",
            "Epoch 135/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.1001\n",
            "Epoch 136/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.0982\n",
            "Epoch 137/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.0895\n",
            "Epoch 138/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.0754\n",
            "Epoch 139/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.0573\n",
            "Epoch 140/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.0360\n",
            "Epoch 141/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.0126\n",
            "Epoch 142/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.9874\n",
            "Epoch 143/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.9610\n",
            "Epoch 144/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.9338\n",
            "Epoch 145/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.9060\n",
            "Epoch 146/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.8778\n",
            "Epoch 147/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.8496\n",
            "Epoch 148/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.8217\n",
            "Epoch 149/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.7944\n",
            "Epoch 150/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.7686\n",
            "Epoch 151/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.7448\n",
            "Epoch 152/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.7238\n",
            "Epoch 153/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.7069\n",
            "Epoch 154/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.6949\n",
            "Epoch 155/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.6886\n",
            "Epoch 156/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.6881\n",
            "Epoch 157/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.6920\n",
            "Epoch 158/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.6976\n",
            "Epoch 159/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.7011\n",
            "Epoch 160/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.7000\n",
            "Epoch 161/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.6933\n",
            "Epoch 162/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.6829\n",
            "Epoch 163/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.6712\n",
            "Epoch 164/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.6600\n",
            "Epoch 165/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.6503\n",
            "Epoch 166/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.6424\n",
            "Epoch 167/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.6362\n",
            "Epoch 168/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.6315\n",
            "Epoch 169/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.6281\n",
            "Epoch 170/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.6256\n",
            "Epoch 171/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.6241\n",
            "Epoch 172/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.6231\n",
            "Epoch 173/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.6224\n",
            "Epoch 174/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.6217\n",
            "Epoch 175/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.6208\n",
            "Epoch 176/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.6193\n",
            "Epoch 177/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.6174\n",
            "Epoch 178/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.6149\n",
            "Epoch 179/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.6120\n",
            "Epoch 180/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.6087\n",
            "Epoch 181/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.6048\n",
            "Epoch 182/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.6007\n",
            "Epoch 183/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.5961\n",
            "Epoch 184/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.5907\n",
            "Epoch 185/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.5846\n",
            "Epoch 186/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.5775\n",
            "Epoch 187/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.5695\n",
            "Epoch 188/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.5613\n",
            "Epoch 189/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.5543\n",
            "Epoch 190/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.5470\n",
            "Epoch 191/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.5350\n",
            "Epoch 192/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.5166\n",
            "Epoch 193/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.4948\n",
            "Epoch 194/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.4737\n",
            "Epoch 195/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.4559\n",
            "Epoch 196/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.4420\n",
            "Epoch 197/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.4305\n",
            "Epoch 198/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.4184\n",
            "Epoch 199/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.4073\n",
            "Epoch 200/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.3973\n",
            "Epoch 201/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.3861\n",
            "Epoch 202/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.3746\n",
            "Epoch 203/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.3653\n",
            "Epoch 204/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.3534\n",
            "Epoch 205/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.3420\n",
            "Epoch 206/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.3328\n",
            "Epoch 207/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.3187\n",
            "Epoch 208/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.3108\n",
            "Epoch 209/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.3007\n",
            "Epoch 210/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.2835\n",
            "Epoch 211/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1.3081\n",
            "Epoch 212/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.2550\n",
            "Epoch 213/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.4030\n",
            "Epoch 214/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.2710\n",
            "Epoch 215/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.6333\n",
            "Epoch 216/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.4447\n",
            "Epoch 217/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1.8661\n",
            "Epoch 218/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.6693\n",
            "Epoch 219/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 1.5917\n",
            "Epoch 220/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.5482\n",
            "Epoch 221/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.5128\n",
            "Epoch 222/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.4769\n",
            "Epoch 223/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.4376\n",
            "Epoch 224/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.3896\n",
            "Epoch 225/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1.3277\n",
            "Epoch 226/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 1.2664\n",
            "Epoch 227/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.2677\n",
            "Epoch 228/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.2664\n",
            "Epoch 229/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.2480\n",
            "Epoch 230/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.7219\n",
            "Epoch 231/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.4896\n",
            "Epoch 232/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.4251\n",
            "Epoch 233/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.0571\n",
            "Epoch 234/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.5826\n",
            "Epoch 235/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.4971\n",
            "Epoch 236/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.3843\n",
            "Epoch 237/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.2585\n",
            "Epoch 238/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.1751\n",
            "Epoch 239/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.1652\n",
            "Epoch 240/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.1063\n",
            "Epoch 241/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.0782\n",
            "Epoch 242/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.0984\n",
            "Epoch 243/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.1525\n",
            "Epoch 244/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.7168\n",
            "Epoch 245/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.4162\n",
            "Epoch 246/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.5328\n",
            "Epoch 247/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.2502\n",
            "Epoch 248/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.1874\n",
            "Epoch 249/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.0721\n",
            "Epoch 250/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.1162\n",
            "Epoch 251/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.9439\n",
            "Epoch 252/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.8930\n",
            "Epoch 253/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.9255\n",
            "Epoch 254/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.1590\n",
            "Epoch 255/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.1200\n",
            "Epoch 256/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.1925\n",
            "Epoch 257/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.8774\n",
            "Epoch 258/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.7886\n",
            "Epoch 259/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.8243\n",
            "Epoch 260/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.8797\n",
            "Epoch 261/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.1441\n",
            "Epoch 262/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.8764\n",
            "Epoch 263/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.9222\n",
            "Epoch 264/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.4288\n",
            "Epoch 265/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.5005\n",
            "Epoch 266/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.1508\n",
            "Epoch 267/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.9577\n",
            "Epoch 268/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.7711\n",
            "Epoch 269/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6963\n",
            "Epoch 270/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5584\n",
            "Epoch 271/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5114\n",
            "Epoch 272/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.4791\n",
            "Epoch 273/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5100\n",
            "Epoch 274/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6784\n",
            "Epoch 275/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5955\n",
            "Epoch 276/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5912\n",
            "Epoch 277/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6193\n",
            "Epoch 278/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6344\n",
            "Epoch 279/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.4045\n",
            "Epoch 280/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.4993\n",
            "Epoch 281/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.7633\n",
            "Epoch 282/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.8175\n",
            "Epoch 283/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6232\n",
            "Epoch 284/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.3662\n",
            "Epoch 285/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.3682\n",
            "Epoch 286/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.4674\n",
            "Epoch 287/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.3939\n",
            "Epoch 288/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.2940\n",
            "Epoch 289/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.2358\n",
            "Epoch 290/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.2171\n",
            "Epoch 291/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.1915\n",
            "Epoch 292/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1818\n",
            "Epoch 293/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.1670\n",
            "Epoch 294/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.1600\n",
            "Epoch 295/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.1479\n",
            "Epoch 296/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.1439\n",
            "Epoch 297/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.1331\n",
            "Epoch 298/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.1327\n",
            "Epoch 299/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.1246\n",
            "Epoch 300/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.1312\n",
            "Epoch 301/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.1324\n",
            "Epoch 302/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.1379\n",
            "Epoch 303/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.1339\n",
            "Epoch 304/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.1230\n",
            "Epoch 305/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0988\n",
            "Epoch 306/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0970\n",
            "Epoch 307/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0900\n",
            "Epoch 308/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0919\n",
            "Epoch 309/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0883\n",
            "Epoch 310/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0933\n",
            "Epoch 311/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0889\n",
            "Epoch 312/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0961\n",
            "Epoch 313/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0902\n",
            "Epoch 314/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0964\n",
            "Epoch 315/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0875\n",
            "Epoch 316/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0943\n",
            "Epoch 317/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0869\n",
            "Epoch 318/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0952\n",
            "Epoch 319/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0893\n",
            "Epoch 320/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0987\n",
            "Epoch 321/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0927\n",
            "Epoch 322/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1023\n",
            "Epoch 323/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0957\n",
            "Epoch 324/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.1067\n",
            "Epoch 325/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.1013\n",
            "Epoch 326/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.1138\n",
            "Epoch 327/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.1076\n",
            "Epoch 328/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.1196\n",
            "Epoch 329/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.1134\n",
            "Epoch 330/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.1219\n",
            "Epoch 331/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.1116\n",
            "Epoch 332/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.1196\n",
            "Epoch 333/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.1097\n",
            "Epoch 334/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.1197\n",
            "Epoch 335/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.1120\n",
            "Epoch 336/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.1215\n",
            "Epoch 337/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.1101\n",
            "Epoch 338/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.1181\n",
            "Epoch 339/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.1060\n",
            "Epoch 340/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1125\n",
            "Epoch 341/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.1011\n",
            "Epoch 342/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1085\n",
            "Epoch 343/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0983\n",
            "Epoch 344/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.1056\n",
            "Epoch 345/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0954\n",
            "Epoch 346/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.1025\n",
            "Epoch 347/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0928\n",
            "Epoch 348/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0979\n",
            "Epoch 349/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0872\n",
            "Epoch 350/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0918\n",
            "Epoch 351/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0818\n",
            "Epoch 352/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0870\n",
            "Epoch 353/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0795\n",
            "Epoch 354/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0843\n",
            "Epoch 355/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0753\n",
            "Epoch 356/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0801\n",
            "Epoch 357/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0733\n",
            "Epoch 358/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0765\n",
            "Epoch 359/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0685\n",
            "Epoch 360/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0707\n",
            "Epoch 361/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0642\n",
            "Epoch 362/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0673\n",
            "Epoch 363/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0615\n",
            "Epoch 364/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0639\n",
            "Epoch 365/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0590\n",
            "Epoch 366/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0611\n",
            "Epoch 367/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0564\n",
            "Epoch 368/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0585\n",
            "Epoch 369/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0533\n",
            "Epoch 370/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0545\n",
            "Epoch 371/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0496\n",
            "Epoch 372/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0508\n",
            "Epoch 373/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0459\n",
            "Epoch 374/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0475\n",
            "Epoch 375/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0438\n",
            "Epoch 376/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0454\n",
            "Epoch 377/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0418\n",
            "Epoch 378/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0427\n",
            "Epoch 379/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0399\n",
            "Epoch 380/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0405\n",
            "Epoch 381/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0369\n",
            "Epoch 382/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0384\n",
            "Epoch 383/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0354\n",
            "Epoch 384/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0365\n",
            "Epoch 385/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0339\n",
            "Epoch 386/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0350\n",
            "Epoch 387/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0321\n",
            "Epoch 388/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0329\n",
            "Epoch 389/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0306\n",
            "Epoch 390/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0311\n",
            "Epoch 391/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0290\n",
            "Epoch 392/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0294\n",
            "Epoch 393/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0276\n",
            "Epoch 394/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0283\n",
            "Epoch 395/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0268\n",
            "Epoch 396/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0279\n",
            "Epoch 397/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0260\n",
            "Epoch 398/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0272\n",
            "Epoch 399/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0257\n",
            "Epoch 400/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0266\n",
            "Epoch 401/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0252\n",
            "Epoch 402/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0259\n",
            "Epoch 403/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0242\n",
            "Epoch 404/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0249\n",
            "Epoch 405/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0236\n",
            "Epoch 406/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0241\n",
            "Epoch 407/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0226\n",
            "Epoch 408/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0236\n",
            "Epoch 409/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0224\n",
            "Epoch 410/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0229\n",
            "Epoch 411/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0218\n",
            "Epoch 412/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0222\n",
            "Epoch 413/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0211\n",
            "Epoch 414/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0214\n",
            "Epoch 415/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0204\n",
            "Epoch 416/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0208\n",
            "Epoch 417/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0199\n",
            "Epoch 418/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0203\n",
            "Epoch 419/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0191\n",
            "Epoch 420/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0195\n",
            "Epoch 421/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0187\n",
            "Epoch 422/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0193\n",
            "Epoch 423/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0184\n",
            "Epoch 424/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0188\n",
            "Epoch 425/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0181\n",
            "Epoch 426/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0185\n",
            "Epoch 427/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0178\n",
            "Epoch 428/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0181\n",
            "Epoch 429/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0174\n",
            "Epoch 430/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0177\n",
            "Epoch 431/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0169\n",
            "Epoch 432/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0171\n",
            "Epoch 433/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0166\n",
            "Epoch 434/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0168\n",
            "Epoch 435/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0160\n",
            "Epoch 436/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0163\n",
            "Epoch 437/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0157\n",
            "Epoch 438/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0161\n",
            "Epoch 439/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0155\n",
            "Epoch 440/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0159\n",
            "Epoch 441/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0153\n",
            "Epoch 442/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0156\n",
            "Epoch 443/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0150\n",
            "Epoch 444/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0152\n",
            "Epoch 445/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0145\n",
            "Epoch 446/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0146\n",
            "Epoch 447/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0140\n",
            "Epoch 448/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0142\n",
            "Epoch 449/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0136\n",
            "Epoch 450/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0137\n",
            "Epoch 451/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0132\n",
            "Epoch 452/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0135\n",
            "Epoch 453/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0130\n",
            "Epoch 454/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0133\n",
            "Epoch 455/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0127\n",
            "Epoch 456/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0130\n",
            "Epoch 457/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0126\n",
            "Epoch 458/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0129\n",
            "Epoch 459/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0124\n",
            "Epoch 460/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0125\n",
            "Epoch 461/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0121\n",
            "Epoch 462/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0123\n",
            "Epoch 463/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0119\n",
            "Epoch 464/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0121\n",
            "Epoch 465/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0116\n",
            "Epoch 466/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0119\n",
            "Epoch 467/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0116\n",
            "Epoch 468/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0118\n",
            "Epoch 469/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0114\n",
            "Epoch 470/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0116\n",
            "Epoch 471/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0113\n",
            "Epoch 472/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0116\n",
            "Epoch 473/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0112\n",
            "Epoch 474/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0115\n",
            "Epoch 475/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0112\n",
            "Epoch 476/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0114\n",
            "Epoch 477/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0111\n",
            "Epoch 478/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0113\n",
            "Epoch 479/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0110\n",
            "Epoch 480/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0111\n",
            "Epoch 481/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0108\n",
            "Epoch 482/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0110\n",
            "Epoch 483/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0107\n",
            "Epoch 484/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0109\n",
            "Epoch 485/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0107\n",
            "Epoch 486/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0107\n",
            "Epoch 487/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0105\n",
            "Epoch 488/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0106\n",
            "Epoch 489/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0104\n",
            "Epoch 490/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0105\n",
            "Epoch 491/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0102\n",
            "Epoch 492/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0103\n",
            "Epoch 493/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0100\n",
            "Epoch 494/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0103\n",
            "Epoch 495/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0100\n",
            "Epoch 496/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0102\n",
            "Epoch 497/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0099\n",
            "Epoch 498/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0100\n",
            "Epoch 499/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0098\n",
            "Epoch 500/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0100\n",
            "Epoch 501/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0097\n",
            "Epoch 502/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0098\n",
            "Epoch 503/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0096\n",
            "Epoch 504/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0097\n",
            "Epoch 505/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0094\n",
            "Epoch 506/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0094\n",
            "Epoch 507/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0093\n",
            "Epoch 508/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0094\n",
            "Epoch 509/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0093\n",
            "Epoch 510/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0093\n",
            "Epoch 511/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0090\n",
            "Epoch 512/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0092\n",
            "Epoch 513/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0090\n",
            "Epoch 514/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0091\n",
            "Epoch 515/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0089\n",
            "Epoch 516/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0090\n",
            "Epoch 517/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0087\n",
            "Epoch 518/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0088\n",
            "Epoch 519/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0086\n",
            "Epoch 520/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0088\n",
            "Epoch 521/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0085\n",
            "Epoch 522/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0086\n",
            "Epoch 523/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0084\n",
            "Epoch 524/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0083\n",
            "Epoch 525/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0082\n",
            "Epoch 526/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0082\n",
            "Epoch 527/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0080\n",
            "Epoch 528/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0082\n",
            "Epoch 529/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0080\n",
            "Epoch 530/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0080\n",
            "Epoch 531/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0078\n",
            "Epoch 532/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0078\n",
            "Epoch 533/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0077\n",
            "Epoch 534/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0078\n",
            "Epoch 535/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0076\n",
            "Epoch 536/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0077\n",
            "Epoch 537/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0076\n",
            "Epoch 538/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0076\n",
            "Epoch 539/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0075\n",
            "Epoch 540/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0076\n",
            "Epoch 541/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0075\n",
            "Epoch 542/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0076\n",
            "Epoch 543/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0074\n",
            "Epoch 544/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0075\n",
            "Epoch 545/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0074\n",
            "Epoch 546/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0075\n",
            "Epoch 547/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0073\n",
            "Epoch 548/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0074\n",
            "Epoch 549/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0073\n",
            "Epoch 550/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0073\n",
            "Epoch 551/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0073\n",
            "Epoch 552/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0073\n",
            "Epoch 553/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0073\n",
            "Epoch 554/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0073\n",
            "Epoch 555/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0071\n",
            "Epoch 556/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0073\n",
            "Epoch 557/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0071\n",
            "Epoch 558/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0072\n",
            "Epoch 559/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0070\n",
            "Epoch 560/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0071\n",
            "Epoch 561/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0071\n",
            "Epoch 562/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0070\n",
            "Epoch 563/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0070\n",
            "Epoch 564/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0070\n",
            "Epoch 565/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0068\n",
            "Epoch 566/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0069\n",
            "Epoch 567/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0067\n",
            "Epoch 568/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0067\n",
            "Epoch 569/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0066\n",
            "Epoch 570/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0068\n",
            "Epoch 571/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0066\n",
            "Epoch 572/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0067\n",
            "Epoch 573/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0066\n",
            "Epoch 574/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0068\n",
            "Epoch 575/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0066\n",
            "Epoch 576/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0066\n",
            "Epoch 577/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0065\n",
            "Epoch 578/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0066\n",
            "Epoch 579/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0066\n",
            "Epoch 580/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0067\n",
            "Epoch 581/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0065\n",
            "Epoch 582/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0066\n",
            "Epoch 583/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0065\n",
            "Epoch 584/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0065\n",
            "Epoch 585/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0066\n",
            "Epoch 586/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0065\n",
            "Epoch 587/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0064\n",
            "Epoch 588/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0066\n",
            "Epoch 589/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0064\n",
            "Epoch 590/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0064\n",
            "Epoch 591/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0063\n",
            "Epoch 592/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0063\n",
            "Epoch 593/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0063\n",
            "Epoch 594/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0063\n",
            "Epoch 595/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0061\n",
            "Epoch 596/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0062\n",
            "Epoch 597/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0061\n",
            "Epoch 598/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0061\n",
            "Epoch 599/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0060\n",
            "Epoch 600/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0060\n",
            "Epoch 601/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0060\n",
            "Epoch 602/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0060\n",
            "Epoch 603/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0059\n",
            "Epoch 604/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0059\n",
            "Epoch 605/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0058\n",
            "Epoch 606/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0058\n",
            "Epoch 607/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0058\n",
            "Epoch 608/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0058\n",
            "Epoch 609/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0057\n",
            "Epoch 610/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0057\n",
            "Epoch 611/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0056\n",
            "Epoch 612/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0056\n",
            "Epoch 613/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0056\n",
            "Epoch 614/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0056\n",
            "Epoch 615/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0054\n",
            "Epoch 616/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0056\n",
            "Epoch 617/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0054\n",
            "Epoch 618/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0056\n",
            "Epoch 619/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0054\n",
            "Epoch 620/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0055\n",
            "Epoch 621/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0054\n",
            "Epoch 622/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0055\n",
            "Epoch 623/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0054\n",
            "Epoch 624/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0055\n",
            "Epoch 625/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0054\n",
            "Epoch 626/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0055\n",
            "Epoch 627/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0054\n",
            "Epoch 628/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0056\n",
            "Epoch 629/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0056\n",
            "Epoch 630/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0058\n",
            "Epoch 631/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0057\n",
            "Epoch 632/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0056\n",
            "Epoch 633/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0058\n",
            "Epoch 634/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0058\n",
            "Epoch 635/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0059\n",
            "Epoch 636/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0060\n",
            "Epoch 637/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0060\n",
            "Epoch 638/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0061\n",
            "Epoch 639/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0062\n",
            "Epoch 640/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0062\n",
            "Epoch 641/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0062\n",
            "Epoch 642/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0062\n",
            "Epoch 643/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0063\n",
            "Epoch 644/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0063\n",
            "Epoch 645/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0063\n",
            "Epoch 646/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0063\n",
            "Epoch 647/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0065\n",
            "Epoch 648/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0065\n",
            "Epoch 649/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0065\n",
            "Epoch 650/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0064\n",
            "Epoch 651/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0065\n",
            "Epoch 652/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0064\n",
            "Epoch 653/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0064\n",
            "Epoch 654/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0064\n",
            "Epoch 655/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0063\n",
            "Epoch 656/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0062\n",
            "Epoch 657/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0062\n",
            "Epoch 658/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0062\n",
            "Epoch 659/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0060\n",
            "Epoch 660/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0060\n",
            "Epoch 661/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0060\n",
            "Epoch 662/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0059\n",
            "Epoch 663/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0058\n",
            "Epoch 664/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0057\n",
            "Epoch 665/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0055\n",
            "Epoch 666/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0055\n",
            "Epoch 667/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0053\n",
            "Epoch 668/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0052\n",
            "Epoch 669/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0051\n",
            "Epoch 670/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0051\n",
            "Epoch 671/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0050\n",
            "Epoch 672/1000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0049\n",
            "Epoch 673/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0047\n",
            "Epoch 674/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0047\n",
            "Epoch 675/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0045\n",
            "Epoch 676/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.0046\n",
            "Epoch 677/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0044\n",
            "Epoch 678/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0045\n",
            "Epoch 679/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0043\n",
            "Epoch 680/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0044\n",
            "Epoch 681/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0042\n",
            "Epoch 682/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0043\n",
            "Epoch 683/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0042\n",
            "Epoch 684/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0042\n",
            "Epoch 685/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0043\n",
            "Epoch 686/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0043\n",
            "Epoch 687/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0043\n",
            "Epoch 688/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0043\n",
            "Epoch 689/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0044\n",
            "Epoch 690/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0043\n",
            "Epoch 691/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0043\n",
            "Epoch 692/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.0045\n",
            "Epoch 693/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0046\n",
            "Epoch 694/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0047\n",
            "Epoch 695/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0048\n",
            "Epoch 696/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0047\n",
            "Epoch 697/1000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.0049\n",
            "Epoch 698/1000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0050\n",
            "Epoch 699/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0053\n",
            "Epoch 700/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0054\n",
            "Epoch 701/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0056\n",
            "Epoch 702/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0058\n",
            "Epoch 703/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0060\n",
            "Epoch 704/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0062\n",
            "Epoch 705/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0065\n",
            "Epoch 706/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0066\n",
            "Epoch 707/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0069\n",
            "Epoch 708/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0070\n",
            "Epoch 709/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0071\n",
            "Epoch 710/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.0071\n",
            "Epoch 711/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0073\n",
            "Epoch 712/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0071\n",
            "Epoch 713/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0073\n",
            "Epoch 714/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0070\n",
            "Epoch 715/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0069\n",
            "Epoch 716/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0068\n",
            "Epoch 717/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0067\n",
            "Epoch 718/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0063\n",
            "Epoch 719/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0063\n",
            "Epoch 720/1000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0060\n",
            "Epoch 721/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0059\n",
            "Epoch 722/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0056\n",
            "Epoch 723/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0055\n",
            "Epoch 724/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0054\n",
            "Epoch 725/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0052\n",
            "Epoch 726/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0049\n",
            "Epoch 727/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0049\n",
            "Epoch 728/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0045\n",
            "Epoch 729/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.0044\n",
            "Epoch 730/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0042\n",
            "Epoch 731/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0042\n",
            "Epoch 732/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0041\n",
            "Epoch 733/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0038\n",
            "Epoch 734/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0038\n",
            "Epoch 735/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0038\n",
            "Epoch 736/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0037\n",
            "Epoch 737/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0036\n",
            "Epoch 738/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0037\n",
            "Epoch 739/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0035\n",
            "Epoch 740/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0036\n",
            "Epoch 741/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0036\n",
            "Epoch 742/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0034\n",
            "Epoch 743/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0034\n",
            "Epoch 744/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0034\n",
            "Epoch 745/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0033\n",
            "Epoch 746/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0034\n",
            "Epoch 747/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0034\n",
            "Epoch 748/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0033\n",
            "Epoch 749/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0033\n",
            "Epoch 750/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0032\n",
            "Epoch 751/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0033\n",
            "Epoch 752/1000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0033\n",
            "Epoch 753/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0032\n",
            "Epoch 754/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0032\n",
            "Epoch 755/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0032\n",
            "Epoch 756/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0034\n",
            "Epoch 757/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0034\n",
            "Epoch 758/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0034\n",
            "Epoch 759/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0034\n",
            "Epoch 760/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0037\n",
            "Epoch 761/1000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0038\n",
            "Epoch 762/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0039\n",
            "Epoch 763/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0040\n",
            "Epoch 764/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0043\n",
            "Epoch 765/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0046\n",
            "Epoch 766/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0047\n",
            "Epoch 767/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0051\n",
            "Epoch 768/1000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0054\n",
            "Epoch 769/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0059\n",
            "Epoch 770/1000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.0062\n",
            "Epoch 771/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0067\n",
            "Epoch 772/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.0070\n",
            "Epoch 773/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0076\n",
            "Epoch 774/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0078\n",
            "Epoch 775/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0083\n",
            "Epoch 776/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0081\n",
            "Epoch 777/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0083\n",
            "Epoch 778/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0080\n",
            "Epoch 779/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0081\n",
            "Epoch 780/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0075\n",
            "Epoch 781/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0072\n",
            "Epoch 782/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0067\n",
            "Epoch 783/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0065\n",
            "Epoch 784/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0059\n",
            "Epoch 785/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0057\n",
            "Epoch 786/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0053\n",
            "Epoch 787/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0050\n",
            "Epoch 788/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0046\n",
            "Epoch 789/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0045\n",
            "Epoch 790/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0042\n",
            "Epoch 791/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0040\n",
            "Epoch 792/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0038\n",
            "Epoch 793/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0036\n",
            "Epoch 794/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0036\n",
            "Epoch 795/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0035\n",
            "Epoch 796/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0034\n",
            "Epoch 797/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0032\n",
            "Epoch 798/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0031\n",
            "Epoch 799/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0031\n",
            "Epoch 800/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0030\n",
            "Epoch 801/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0029\n",
            "Epoch 802/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0030\n",
            "Epoch 803/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0028\n",
            "Epoch 804/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0028\n",
            "Epoch 805/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0028\n",
            "Epoch 806/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0027\n",
            "Epoch 807/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0027\n",
            "Epoch 808/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0027\n",
            "Epoch 809/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0028\n",
            "Epoch 810/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0026\n",
            "Epoch 811/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0028\n",
            "Epoch 812/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0027\n",
            "Epoch 813/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0026\n",
            "Epoch 814/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0027\n",
            "Epoch 815/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0027\n",
            "Epoch 816/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0026\n",
            "Epoch 817/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0026\n",
            "Epoch 818/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0028\n",
            "Epoch 819/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0027\n",
            "Epoch 820/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0027\n",
            "Epoch 821/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0026\n",
            "Epoch 822/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0027\n",
            "Epoch 823/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0027\n",
            "Epoch 824/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0027\n",
            "Epoch 825/1000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0026\n",
            "Epoch 826/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0026\n",
            "Epoch 827/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0025\n",
            "Epoch 828/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0026\n",
            "Epoch 829/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0025\n",
            "Epoch 830/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0025\n",
            "Epoch 831/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0025\n",
            "Epoch 832/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0025\n",
            "Epoch 833/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0025\n",
            "Epoch 834/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0024\n",
            "Epoch 835/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0024\n",
            "Epoch 836/1000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0024\n",
            "Epoch 837/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0024\n",
            "Epoch 838/1000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.0023\n",
            "Epoch 839/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0023\n",
            "Epoch 840/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0024\n",
            "Epoch 841/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0024\n",
            "Epoch 842/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0024\n",
            "Epoch 843/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0025\n",
            "Epoch 844/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0024\n",
            "Epoch 845/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0024\n",
            "Epoch 846/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0024\n",
            "Epoch 847/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0024\n",
            "Epoch 848/1000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.0023\n",
            "Epoch 849/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0024\n",
            "Epoch 850/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0024\n",
            "Epoch 851/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0025\n",
            "Epoch 852/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0024\n",
            "Epoch 853/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0024\n",
            "Epoch 854/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0024\n",
            "Epoch 855/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0024\n",
            "Epoch 856/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0025\n",
            "Epoch 857/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0024\n",
            "Epoch 858/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0025\n",
            "Epoch 859/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0025\n",
            "Epoch 860/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0025\n",
            "Epoch 861/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0025\n",
            "Epoch 862/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0026\n",
            "Epoch 863/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0028\n",
            "Epoch 864/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0028\n",
            "Epoch 865/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0030\n",
            "Epoch 866/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0033\n",
            "Epoch 867/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0036\n",
            "Epoch 868/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0040\n",
            "Epoch 869/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0047\n",
            "Epoch 870/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0054\n",
            "Epoch 871/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0064\n",
            "Epoch 872/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0072\n",
            "Epoch 873/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0086\n",
            "Epoch 874/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0092\n",
            "Epoch 875/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0107\n",
            "Epoch 876/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0106\n",
            "Epoch 877/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0114\n",
            "Epoch 878/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0105\n",
            "Epoch 879/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0107\n",
            "Epoch 880/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0094\n",
            "Epoch 881/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0092\n",
            "Epoch 882/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0079\n",
            "Epoch 883/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0075\n",
            "Epoch 884/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0066\n",
            "Epoch 885/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0062\n",
            "Epoch 886/1000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.0055\n",
            "Epoch 887/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0053\n",
            "Epoch 888/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0049\n",
            "Epoch 889/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0046\n",
            "Epoch 890/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0042\n",
            "Epoch 891/1000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0040\n",
            "Epoch 892/1000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0038\n",
            "Epoch 893/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0035\n",
            "Epoch 894/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0034\n",
            "Epoch 895/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0033\n",
            "Epoch 896/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0031\n",
            "Epoch 897/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0030\n",
            "Epoch 898/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0029\n",
            "Epoch 899/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0028\n",
            "Epoch 900/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0028\n",
            "Epoch 901/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0027\n",
            "Epoch 902/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0027\n",
            "Epoch 903/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0027\n",
            "Epoch 904/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0026\n",
            "Epoch 905/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0026\n",
            "Epoch 906/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.0026\n",
            "Epoch 907/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0025\n",
            "Epoch 908/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0025\n",
            "Epoch 909/1000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0025\n",
            "Epoch 910/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0024\n",
            "Epoch 911/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0024\n",
            "Epoch 912/1000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.0024\n",
            "Epoch 913/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0025\n",
            "Epoch 914/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0025\n",
            "Epoch 915/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0025\n",
            "Epoch 916/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0025\n",
            "Epoch 917/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0024\n",
            "Epoch 918/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0023\n",
            "Epoch 919/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0025\n",
            "Epoch 920/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0024\n",
            "Epoch 921/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0023\n",
            "Epoch 922/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0023\n",
            "Epoch 923/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0023\n",
            "Epoch 924/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0024\n",
            "Epoch 925/1000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.0023\n",
            "Epoch 926/1000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.0023\n",
            "Epoch 927/1000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.0023\n",
            "Epoch 928/1000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.0023\n",
            "Epoch 929/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0022\n",
            "Epoch 930/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0022\n",
            "Epoch 931/1000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0023\n",
            "Epoch 932/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0023\n",
            "Epoch 933/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0022\n",
            "Epoch 934/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0022\n",
            "Epoch 935/1000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0022\n",
            "Epoch 936/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0023\n",
            "Epoch 937/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0023\n",
            "Epoch 938/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0023\n",
            "Epoch 939/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0023\n",
            "Epoch 940/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0022\n",
            "Epoch 941/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0023\n",
            "Epoch 942/1000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.0024\n",
            "Epoch 943/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0023\n",
            "Epoch 944/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0022\n",
            "Epoch 945/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0023\n",
            "Epoch 946/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0023\n",
            "Epoch 947/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0022\n",
            "Epoch 948/1000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.0023\n",
            "Epoch 949/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0023\n",
            "Epoch 950/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0023\n",
            "Epoch 951/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0024\n",
            "Epoch 952/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0024\n",
            "Epoch 953/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0024\n",
            "Epoch 954/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0026\n",
            "Epoch 955/1000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0027\n",
            "Epoch 956/1000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.0028\n",
            "Epoch 957/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.0030\n",
            "Epoch 958/1000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.0033\n",
            "Epoch 959/1000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0036\n",
            "Epoch 960/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0040\n",
            "Epoch 961/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0043\n",
            "Epoch 962/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0049\n",
            "Epoch 963/1000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.0053\n",
            "Epoch 964/1000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0061\n",
            "Epoch 965/1000\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0064\n",
            "Epoch 966/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0073\n",
            "Epoch 967/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0073\n",
            "Epoch 968/1000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.0079\n",
            "Epoch 969/1000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.0077\n",
            "Epoch 970/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.0082\n",
            "Epoch 971/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0075\n",
            "Epoch 972/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0075\n",
            "Epoch 973/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0067\n",
            "Epoch 974/1000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.0067\n",
            "Epoch 975/1000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.0060\n",
            "Epoch 976/1000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.0059\n",
            "Epoch 977/1000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.0052\n",
            "Epoch 978/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0050\n",
            "Epoch 979/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0046\n",
            "Epoch 980/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0044\n",
            "Epoch 981/1000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.0041\n",
            "Epoch 982/1000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0039\n",
            "Epoch 983/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0037\n",
            "Epoch 984/1000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.0035\n",
            "Epoch 985/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0034\n",
            "Epoch 986/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0033\n",
            "Epoch 987/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0031\n",
            "Epoch 988/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0029\n",
            "Epoch 989/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0028\n",
            "Epoch 990/1000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.0028\n",
            "Epoch 991/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0028\n",
            "Epoch 992/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0027\n",
            "Epoch 993/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0026\n",
            "Epoch 994/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0026\n",
            "Epoch 995/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0026\n",
            "Epoch 996/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0025\n",
            "Epoch 997/1000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.0026\n",
            "Epoch 998/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0026\n",
            "Epoch 999/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0027\n",
            "Epoch 1000/1000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.0024\n",
            " Train loss: 0.002591808559373021\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-b78fc7577382>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# evaluate the model on the test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregressor_mae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_Ecodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# calculate the evaluation metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nSpecified a list with shape [42,24] from a tensor with shape [32,24]\n\t [[{{node TensorArrayUnstack/TensorListFromTensor}}]]\n\t [[model_1/lstm_2/PartitionedCall]] [Op:__inference_predict_function_27287]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras_preprocessing\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# pad sequence\n",
        "# English\n",
        "padded_Ecodes = pad_sequences(Ecodes, padding='post', dtype='float32')\n",
        "padded_EcodesP = padded_Ecodes\n",
        "padded_EcodesP = padded_EcodesP.reshape(42, 3, 21)\n",
        "padded_EcodesP = np.pad(padded_EcodesP, ((0, 0), (0, 1),(0, 3)))\n",
        "padded_Ecodes = padded_EcodesP.reshape(42, 4, 24, 1)\n",
        "\n",
        "# Persian\n",
        "padded_Pcodes = pad_sequences(Pcodes, padding='post', dtype='float32')\n",
        "padded_Pcodes = padded_Pcodes.reshape(42, 4, 24, 1)\n",
        "\n",
        "# Define the model\n",
        "batch_size = 42\n",
        "epochs = 50\n",
        "timesteps = 4\n",
        "inputs = tf.keras.layers.Input(batch_shape=(batch_size, timesteps, 24))\n",
        "lstm_1 = tf.keras.layers.LSTM(100, activation='tanh', stateful=True, return_sequences=True)(inputs)\n",
        "lstm_2 = tf.keras.layers.LSTM(100, activation='relu', stateful=True, return_sequences=True)(lstm_1)\n",
        "output = tf.keras.layers.Dense(units=24)(lstm_2)\n",
        "regressor = tf.keras.Model(inputs=inputs, outputs=output)\n",
        "\n",
        "# Compile the model with optimization algorithm, loss function, and evaluation metrics\n",
        "regressor.compile(optimizer=\"SGD\", loss=\"mse\", metrics=[tf.keras.metrics.MeanSquaredError(), tf.keras.metrics.MeanAbsoluteError(), tf.keras.metrics.RootMeanSquaredError(), tf.keras.metrics.MeanAbsolutePercentageError()])\n",
        "\n",
        "# Print the model summary\n",
        "regressor.summary()\n",
        "\n",
        "# Train the model and save the history of training\n",
        "history = regressor.fit(padded_Ecodes, padded_Pcodes, epochs=100, batch_size=batch_size)\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "score = regressor.evaluate(padded_Ecodes, padded_Pcodes, batch_size=batch_size, verbose=0)\n",
        "\n",
        "# Compute additional evaluation metrics\n",
        "y_true = padded_Pcodes.reshape(-1, 24)\n",
        "y_pred = regressor.predict(padded_Ecodes, batch_size=42).reshape(-1, 24)\n",
        "mae = mean_absolute_error(y_true, y_pred)\n",
        "mse = mean_squared_error(y_true, y_pred)\n",
        "r2 = r2_score(y_true, y_pred)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Mean Squared Error:\", score[1])\n",
        "print(\"Mean Absolute Error:\", score[2])\n",
        "print(\"Root Mean Squared Error:\", score[3])\n",
        "print(\"Mean Absolute Percentage Error:\", score[4])\n",
        "print(\"Mean Absolute Error (MAE):\", mae)\n",
        "print(\"Mean Squared Error (MSE):\", mse)\n",
        "print(\"R^2 Score:\", r2)\n",
        "\n",
        "# Plot the validation loss\n",
        "pd.DataFrame(history.history).plot()\n",
        "plt.title(\"Validation Loss\")\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VspaQa8tyWWm",
        "outputId": "c16f2043-32a5-4490-8ca0-ca50c7ea83bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras_preprocessing in /usr/local/lib/python3.9/dist-packages (1.1.2)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.9/dist-packages (from keras_preprocessing) (1.22.4)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.9/dist-packages (from keras_preprocessing) (1.16.0)\n",
            "Model: \"model_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_10 (InputLayer)       [(42, 4, 24)]             0         \n",
            "                                                                 \n",
            " lstm_18 (LSTM)              (42, 4, 100)              50000     \n",
            "                                                                 \n",
            " lstm_19 (LSTM)              (42, 4, 100)              80400     \n",
            "                                                                 \n",
            " dense_9 (Dense)             (42, 4, 24)               2424      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 132,824\n",
            "Trainable params: 132,824\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.1282 - mean_squared_error: 3.1282 - mean_absolute_error: 0.8718 - root_mean_squared_error: 1.7687 - mean_absolute_percentage_error: 16275365.0000\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 3.1094 - mean_squared_error: 3.1094 - mean_absolute_error: 0.8876 - root_mean_squared_error: 1.7633 - mean_absolute_percentage_error: 36555188.0000\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.0963 - mean_squared_error: 3.0963 - mean_absolute_error: 0.8953 - root_mean_squared_error: 1.7596 - mean_absolute_percentage_error: 47312196.0000\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 3.0841 - mean_squared_error: 3.0841 - mean_absolute_error: 0.8978 - root_mean_squared_error: 1.7562 - mean_absolute_percentage_error: 52327112.0000\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 3.0714 - mean_squared_error: 3.0714 - mean_absolute_error: 0.8983 - root_mean_squared_error: 1.7525 - mean_absolute_percentage_error: 54928944.0000\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.0582 - mean_squared_error: 3.0582 - mean_absolute_error: 0.8979 - root_mean_squared_error: 1.7488 - mean_absolute_percentage_error: 56716080.0000\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.0448 - mean_squared_error: 3.0448 - mean_absolute_error: 0.8974 - root_mean_squared_error: 1.7449 - mean_absolute_percentage_error: 58263288.0000\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.0313 - mean_squared_error: 3.0313 - mean_absolute_error: 0.8969 - root_mean_squared_error: 1.7411 - mean_absolute_percentage_error: 59756936.0000\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.0180 - mean_squared_error: 3.0180 - mean_absolute_error: 0.8964 - root_mean_squared_error: 1.7372 - mean_absolute_percentage_error: 61299644.0000\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.0046 - mean_squared_error: 3.0046 - mean_absolute_error: 0.8960 - root_mean_squared_error: 1.7334 - mean_absolute_percentage_error: 62875892.0000\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.9914 - mean_squared_error: 2.9914 - mean_absolute_error: 0.8957 - root_mean_squared_error: 1.7296 - mean_absolute_percentage_error: 64565856.0000\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.9784 - mean_squared_error: 2.9784 - mean_absolute_error: 0.8955 - root_mean_squared_error: 1.7258 - mean_absolute_percentage_error: 66417700.0000\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.9654 - mean_squared_error: 2.9654 - mean_absolute_error: 0.8957 - root_mean_squared_error: 1.7220 - mean_absolute_percentage_error: 68553784.0000\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.9527 - mean_squared_error: 2.9527 - mean_absolute_error: 0.8959 - root_mean_squared_error: 1.7183 - mean_absolute_percentage_error: 70704736.0000\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.9401 - mean_squared_error: 2.9401 - mean_absolute_error: 0.8962 - root_mean_squared_error: 1.7147 - mean_absolute_percentage_error: 72940832.0000\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.9275 - mean_squared_error: 2.9275 - mean_absolute_error: 0.8966 - root_mean_squared_error: 1.7110 - mean_absolute_percentage_error: 75251856.0000\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.9148 - mean_squared_error: 2.9148 - mean_absolute_error: 0.8970 - root_mean_squared_error: 1.7073 - mean_absolute_percentage_error: 77651392.0000\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.9020 - mean_squared_error: 2.9020 - mean_absolute_error: 0.8975 - root_mean_squared_error: 1.7035 - mean_absolute_percentage_error: 80194600.0000\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.8890 - mean_squared_error: 2.8890 - mean_absolute_error: 0.8981 - root_mean_squared_error: 1.6997 - mean_absolute_percentage_error: 82816904.0000\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.8759 - mean_squared_error: 2.8759 - mean_absolute_error: 0.8986 - root_mean_squared_error: 1.6958 - mean_absolute_percentage_error: 85477256.0000\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.8627 - mean_squared_error: 2.8627 - mean_absolute_error: 0.8992 - root_mean_squared_error: 1.6920 - mean_absolute_percentage_error: 88170456.0000\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.8496 - mean_squared_error: 2.8496 - mean_absolute_error: 0.8998 - root_mean_squared_error: 1.6881 - mean_absolute_percentage_error: 90897584.0000\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.8364 - mean_squared_error: 2.8364 - mean_absolute_error: 0.9004 - root_mean_squared_error: 1.6842 - mean_absolute_percentage_error: 93658840.0000\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.8232 - mean_squared_error: 2.8232 - mean_absolute_error: 0.9011 - root_mean_squared_error: 1.6802 - mean_absolute_percentage_error: 96460712.0000\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.8098 - mean_squared_error: 2.8098 - mean_absolute_error: 0.9017 - root_mean_squared_error: 1.6763 - mean_absolute_percentage_error: 99303680.0000\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.7965 - mean_squared_error: 2.7965 - mean_absolute_error: 0.9023 - root_mean_squared_error: 1.6723 - mean_absolute_percentage_error: 102181192.0000\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.7831 - mean_squared_error: 2.7831 - mean_absolute_error: 0.9030 - root_mean_squared_error: 1.6683 - mean_absolute_percentage_error: 105077464.0000\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.7694 - mean_squared_error: 2.7694 - mean_absolute_error: 0.9036 - root_mean_squared_error: 1.6642 - mean_absolute_percentage_error: 108012120.0000\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.7556 - mean_squared_error: 2.7556 - mean_absolute_error: 0.9042 - root_mean_squared_error: 1.6600 - mean_absolute_percentage_error: 111010560.0000\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.7416 - mean_squared_error: 2.7416 - mean_absolute_error: 0.9048 - root_mean_squared_error: 1.6558 - mean_absolute_percentage_error: 114073792.0000\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.7274 - mean_squared_error: 2.7274 - mean_absolute_error: 0.9054 - root_mean_squared_error: 1.6515 - mean_absolute_percentage_error: 117204784.0000\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.7131 - mean_squared_error: 2.7131 - mean_absolute_error: 0.9060 - root_mean_squared_error: 1.6472 - mean_absolute_percentage_error: 120394384.0000\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.6987 - mean_squared_error: 2.6987 - mean_absolute_error: 0.9067 - root_mean_squared_error: 1.6428 - mean_absolute_percentage_error: 123630984.0000\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.6840 - mean_squared_error: 2.6840 - mean_absolute_error: 0.9073 - root_mean_squared_error: 1.6383 - mean_absolute_percentage_error: 126925592.0000\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.6691 - mean_squared_error: 2.6691 - mean_absolute_error: 0.9079 - root_mean_squared_error: 1.6337 - mean_absolute_percentage_error: 130291480.0000\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.6540 - mean_squared_error: 2.6540 - mean_absolute_error: 0.9085 - root_mean_squared_error: 1.6291 - mean_absolute_percentage_error: 133736664.0000\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.6385 - mean_squared_error: 2.6385 - mean_absolute_error: 0.9091 - root_mean_squared_error: 1.6244 - mean_absolute_percentage_error: 137258832.0000\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.6228 - mean_squared_error: 2.6228 - mean_absolute_error: 0.9097 - root_mean_squared_error: 1.6195 - mean_absolute_percentage_error: 140861856.0000\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.6068 - mean_squared_error: 2.6068 - mean_absolute_error: 0.9103 - root_mean_squared_error: 1.6146 - mean_absolute_percentage_error: 144559056.0000\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.5905 - mean_squared_error: 2.5905 - mean_absolute_error: 0.9108 - root_mean_squared_error: 1.6095 - mean_absolute_percentage_error: 148352272.0000\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.5739 - mean_squared_error: 2.5739 - mean_absolute_error: 0.9114 - root_mean_squared_error: 1.6043 - mean_absolute_percentage_error: 152254832.0000\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.5570 - mean_squared_error: 2.5570 - mean_absolute_error: 0.9120 - root_mean_squared_error: 1.5991 - mean_absolute_percentage_error: 156278192.0000\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.5398 - mean_squared_error: 2.5398 - mean_absolute_error: 0.9127 - root_mean_squared_error: 1.5937 - mean_absolute_percentage_error: 160428672.0000\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.5224 - mean_squared_error: 2.5224 - mean_absolute_error: 0.9133 - root_mean_squared_error: 1.5882 - mean_absolute_percentage_error: 164699616.0000\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.5047 - mean_squared_error: 2.5047 - mean_absolute_error: 0.9140 - root_mean_squared_error: 1.5826 - mean_absolute_percentage_error: 169085024.0000\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.4867 - mean_squared_error: 2.4867 - mean_absolute_error: 0.9147 - root_mean_squared_error: 1.5769 - mean_absolute_percentage_error: 173602432.0000\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.4684 - mean_squared_error: 2.4684 - mean_absolute_error: 0.9154 - root_mean_squared_error: 1.5711 - mean_absolute_percentage_error: 178254064.0000\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.4498 - mean_squared_error: 2.4498 - mean_absolute_error: 0.9161 - root_mean_squared_error: 1.5652 - mean_absolute_percentage_error: 183034624.0000\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.4307 - mean_squared_error: 2.4307 - mean_absolute_error: 0.9167 - root_mean_squared_error: 1.5591 - mean_absolute_percentage_error: 187959392.0000\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.4112 - mean_squared_error: 2.4112 - mean_absolute_error: 0.9174 - root_mean_squared_error: 1.5528 - mean_absolute_percentage_error: 193057936.0000\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.3912 - mean_squared_error: 2.3912 - mean_absolute_error: 0.9181 - root_mean_squared_error: 1.5463 - mean_absolute_percentage_error: 198360144.0000\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.3707 - mean_squared_error: 2.3707 - mean_absolute_error: 0.9188 - root_mean_squared_error: 1.5397 - mean_absolute_percentage_error: 203881728.0000\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.3497 - mean_squared_error: 2.3497 - mean_absolute_error: 0.9195 - root_mean_squared_error: 1.5329 - mean_absolute_percentage_error: 209633200.0000\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.3283 - mean_squared_error: 2.3283 - mean_absolute_error: 0.9202 - root_mean_squared_error: 1.5259 - mean_absolute_percentage_error: 215630464.0000\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.3062 - mean_squared_error: 2.3062 - mean_absolute_error: 0.9209 - root_mean_squared_error: 1.5186 - mean_absolute_percentage_error: 221880976.0000\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.2836 - mean_squared_error: 2.2836 - mean_absolute_error: 0.9216 - root_mean_squared_error: 1.5111 - mean_absolute_percentage_error: 228420800.0000\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.2602 - mean_squared_error: 2.2602 - mean_absolute_error: 0.9224 - root_mean_squared_error: 1.5034 - mean_absolute_percentage_error: 235288304.0000\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.2363 - mean_squared_error: 2.2363 - mean_absolute_error: 0.9231 - root_mean_squared_error: 1.4954 - mean_absolute_percentage_error: 242518400.0000\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.2117 - mean_squared_error: 2.2117 - mean_absolute_error: 0.9239 - root_mean_squared_error: 1.4872 - mean_absolute_percentage_error: 250154128.0000\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.1864 - mean_squared_error: 2.1864 - mean_absolute_error: 0.9247 - root_mean_squared_error: 1.4786 - mean_absolute_percentage_error: 258234960.0000\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.1604 - mean_squared_error: 2.1604 - mean_absolute_error: 0.9255 - root_mean_squared_error: 1.4698 - mean_absolute_percentage_error: 266794816.0000\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.1338 - mean_squared_error: 2.1338 - mean_absolute_error: 0.9263 - root_mean_squared_error: 1.4608 - mean_absolute_percentage_error: 275876000.0000\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.1066 - mean_squared_error: 2.1066 - mean_absolute_error: 0.9272 - root_mean_squared_error: 1.4514 - mean_absolute_percentage_error: 285532000.0000\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.0788 - mean_squared_error: 2.0788 - mean_absolute_error: 0.9282 - root_mean_squared_error: 1.4418 - mean_absolute_percentage_error: 295872672.0000\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.0506 - mean_squared_error: 2.0506 - mean_absolute_error: 0.9297 - root_mean_squared_error: 1.4320 - mean_absolute_percentage_error: 307065568.0000\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.0220 - mean_squared_error: 2.0220 - mean_absolute_error: 0.9323 - root_mean_squared_error: 1.4220 - mean_absolute_percentage_error: 319158816.0000\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.9930 - mean_squared_error: 1.9930 - mean_absolute_error: 0.9368 - root_mean_squared_error: 1.4117 - mean_absolute_percentage_error: 332183904.0000\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.9640 - mean_squared_error: 1.9640 - mean_absolute_error: 0.9420 - root_mean_squared_error: 1.4014 - mean_absolute_percentage_error: 346250304.0000\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.9351 - mean_squared_error: 1.9351 - mean_absolute_error: 0.9474 - root_mean_squared_error: 1.3911 - mean_absolute_percentage_error: 361442144.0000\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.9068 - mean_squared_error: 1.9068 - mean_absolute_error: 0.9532 - root_mean_squared_error: 1.3809 - mean_absolute_percentage_error: 377917792.0000\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.8795 - mean_squared_error: 1.8795 - mean_absolute_error: 0.9594 - root_mean_squared_error: 1.3709 - mean_absolute_percentage_error: 395764896.0000\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.8538 - mean_squared_error: 1.8538 - mean_absolute_error: 0.9656 - root_mean_squared_error: 1.3616 - mean_absolute_percentage_error: 414941952.0000\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.8310 - mean_squared_error: 1.8310 - mean_absolute_error: 0.9721 - root_mean_squared_error: 1.3531 - mean_absolute_percentage_error: 435657568.0000\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.8123 - mean_squared_error: 1.8123 - mean_absolute_error: 0.9789 - root_mean_squared_error: 1.3462 - mean_absolute_percentage_error: 457981408.0000\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.7994 - mean_squared_error: 1.7994 - mean_absolute_error: 0.9857 - root_mean_squared_error: 1.3414 - mean_absolute_percentage_error: 481755520.0000\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.7934 - mean_squared_error: 1.7934 - mean_absolute_error: 0.9928 - root_mean_squared_error: 1.3392 - mean_absolute_percentage_error: 506352448.0000\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.7952 - mean_squared_error: 1.7952 - mean_absolute_error: 1.0021 - root_mean_squared_error: 1.3399 - mean_absolute_percentage_error: 530597024.0000\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.8039 - mean_squared_error: 1.8039 - mean_absolute_error: 1.0110 - root_mean_squared_error: 1.3431 - mean_absolute_percentage_error: 552624960.0000\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.8163 - mean_squared_error: 1.8163 - mean_absolute_error: 1.0181 - root_mean_squared_error: 1.3477 - mean_absolute_percentage_error: 570036544.0000\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.8265 - mean_squared_error: 1.8265 - mean_absolute_error: 1.0218 - root_mean_squared_error: 1.3515 - mean_absolute_percentage_error: 580559744.0000\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.8274 - mean_squared_error: 1.8274 - mean_absolute_error: 1.0189 - root_mean_squared_error: 1.3518 - mean_absolute_percentage_error: 581992768.0000\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.8159 - mean_squared_error: 1.8159 - mean_absolute_error: 1.0111 - root_mean_squared_error: 1.3476 - mean_absolute_percentage_error: 575062144.0000\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.7946 - mean_squared_error: 1.7946 - mean_absolute_error: 0.9975 - root_mean_squared_error: 1.3396 - mean_absolute_percentage_error: 560181824.0000\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.7693 - mean_squared_error: 1.7693 - mean_absolute_error: 0.9812 - root_mean_squared_error: 1.3302 - mean_absolute_percentage_error: 541790720.0000\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.7454 - mean_squared_error: 1.7454 - mean_absolute_error: 0.9653 - root_mean_squared_error: 1.3211 - mean_absolute_percentage_error: 524034432.0000\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.7250 - mean_squared_error: 1.7250 - mean_absolute_error: 0.9511 - root_mean_squared_error: 1.3134 - mean_absolute_percentage_error: 508656352.0000\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.7088 - mean_squared_error: 1.7088 - mean_absolute_error: 0.9390 - root_mean_squared_error: 1.3072 - mean_absolute_percentage_error: 496123808.0000\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.6965 - mean_squared_error: 1.6965 - mean_absolute_error: 0.9302 - root_mean_squared_error: 1.3025 - mean_absolute_percentage_error: 487811648.0000\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.6875 - mean_squared_error: 1.6875 - mean_absolute_error: 0.9241 - root_mean_squared_error: 1.2990 - mean_absolute_percentage_error: 482785184.0000\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.6811 - mean_squared_error: 1.6811 - mean_absolute_error: 0.9196 - root_mean_squared_error: 1.2966 - mean_absolute_percentage_error: 479766240.0000\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.6769 - mean_squared_error: 1.6769 - mean_absolute_error: 0.9161 - root_mean_squared_error: 1.2949 - mean_absolute_percentage_error: 478055040.0000\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.6738 - mean_squared_error: 1.6738 - mean_absolute_error: 0.9132 - root_mean_squared_error: 1.2937 - mean_absolute_percentage_error: 476959808.0000\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.6715 - mean_squared_error: 1.6715 - mean_absolute_error: 0.9106 - root_mean_squared_error: 1.2929 - mean_absolute_percentage_error: 475964064.0000\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.6689 - mean_squared_error: 1.6689 - mean_absolute_error: 0.9079 - root_mean_squared_error: 1.2919 - mean_absolute_percentage_error: 474611904.0000\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.6660 - mean_squared_error: 1.6660 - mean_absolute_error: 0.9049 - root_mean_squared_error: 1.2907 - mean_absolute_percentage_error: 472506080.0000\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.6622 - mean_squared_error: 1.6622 - mean_absolute_error: 0.9017 - root_mean_squared_error: 1.2893 - mean_absolute_percentage_error: 469792224.0000\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.6578 - mean_squared_error: 1.6578 - mean_absolute_error: 0.8983 - root_mean_squared_error: 1.2875 - mean_absolute_percentage_error: 466599008.0000\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.6529 - mean_squared_error: 1.6529 - mean_absolute_error: 0.8950 - root_mean_squared_error: 1.2857 - mean_absolute_percentage_error: 463287136.0000\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.6480 - mean_squared_error: 1.6480 - mean_absolute_error: 0.8915 - root_mean_squared_error: 1.2837 - mean_absolute_percentage_error: 459860320.0000\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.6433 - mean_squared_error: 1.6433 - mean_absolute_error: 0.8883 - root_mean_squared_error: 1.2819 - mean_absolute_percentage_error: 456538880.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7f0989f37310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 552ms/step\n",
            "Test loss: 1.6389901638031006\n",
            "Mean Squared Error: 1.6389901638031006\n",
            "Mean Absolute Error: 0.8852368593215942\n",
            "Root Mean Squared Error: 1.2802305221557617\n",
            "Mean Absolute Percentage Error: 453523840.0\n",
            "Mean Absolute Error (MAE): 0.8910604\n",
            "Mean Squared Error (MSE): 1.6476883\n",
            "R^2 Score: -0.06276010363871824\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# plot the training and validation loss over each epoch\n",
        "plt.plot(history.history['loss'], label='train')\n",
        "#plt.plot(history.history['val_loss'], label='val')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# plot the training and validation accuracy over each epoch\n",
        "plt.plot(history.history['accuracy'], label='train')\n",
        "plt.plot(history.history['val_accuracy'], label='val')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "id": "o6i9ouRn7FM1",
        "outputId": "fb031fa6-a8b3-4b54-ef7b-fae243165de8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-bbe60cd30fed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# plot the training and validation accuracy over each epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'accuracy'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "############Second model########################\n",
        "\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense\n",
        "from keras.layers import Activation, Dense, RepeatVector\n",
        "from keras.layers import TimeDistributed\n",
        "batch_size = 20\n",
        "epochs = 10\n",
        "timesteps = 4\n",
        "X_train, X_test, y_train, y_test = train_test_split(padded_Ecodes, padded_Pcodes, test_size=0.33, random_state=42)\n",
        "tf.keras.backend.clear_session()\n",
        "model = keras.Sequential()\n",
        "model.add(LSTM(50, activation='relu', input_shape=(timesteps, 24)))\n",
        "model.add(RepeatVector(4))\n",
        "model.add(LSTM(100, activation='relu', return_sequences=True))\n",
        "model.add(TimeDistributed(Dense(24)))\n",
        "#optimizer = \"rmsprop\", loss='sparse_categorical_crossentropy'\n",
        "model.compile(optimizer='adam', loss='mae', metrics=['mse'])\n",
        "#model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['mse'])\n",
        "#model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
        "history = model.fit(X_train, y_train, epochs=500, validation_split=0.2, verbose=1)\n",
        "score = model.evaluate(X_test, y_test, batch_size=20, verbose=1)\n",
        "\n",
        "train_predict = model.predict(X_train)\n",
        "test_predict = model.predict(X_test)\n",
        "history_dict = history.history\n",
        "del history_dict['loss']\n",
        "del history_dict['mse']\n",
        "pd.DataFrame(history.history).plot()\n",
        "plt.title(\"Loss\")\n",
        "plt.show()\n",
        "print(' Validation loss:', score)\n",
        "print(model.metrics_names)"
      ],
      "metadata": {
        "id": "PAbPYk8Gb1QT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e2667109-440c-46b2-84b1-8df0af861e69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.8813 - mse: 3.1502 - val_loss: 0.8735 - val_mse: 3.1338\n",
            "Epoch 2/500\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.8735 - mse: 3.1380 - val_loss: 0.8680 - val_mse: 3.1253\n",
            "Epoch 3/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.8680 - mse: 3.1295 - val_loss: 0.8649 - val_mse: 3.1190\n",
            "Epoch 4/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.8649 - mse: 3.1232 - val_loss: 0.8632 - val_mse: 3.1128\n",
            "Epoch 5/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.8633 - mse: 3.1170 - val_loss: 0.8615 - val_mse: 3.1085\n",
            "Epoch 6/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.8615 - mse: 3.1127 - val_loss: 0.8595 - val_mse: 3.1054\n",
            "Epoch 7/500\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.8595 - mse: 3.1096 - val_loss: 0.8583 - val_mse: 3.1031\n",
            "Epoch 8/500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.8583 - mse: 3.1073 - val_loss: 0.8574 - val_mse: 3.1011\n",
            "Epoch 9/500\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.8574 - mse: 3.1053 - val_loss: 0.8566 - val_mse: 3.0984\n",
            "Epoch 10/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.8566 - mse: 3.1026 - val_loss: 0.8559 - val_mse: 3.0950\n",
            "Epoch 11/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.8559 - mse: 3.0992 - val_loss: 0.8551 - val_mse: 3.0904\n",
            "Epoch 12/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.8551 - mse: 3.0947 - val_loss: 0.8541 - val_mse: 3.0848\n",
            "Epoch 13/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.8541 - mse: 3.0890 - val_loss: 0.8530 - val_mse: 3.0781\n",
            "Epoch 14/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.8531 - mse: 3.0824 - val_loss: 0.8520 - val_mse: 3.0711\n",
            "Epoch 15/500\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.8520 - mse: 3.0754 - val_loss: 0.8510 - val_mse: 3.0637\n",
            "Epoch 16/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.8510 - mse: 3.0680 - val_loss: 0.8500 - val_mse: 3.0560\n",
            "Epoch 17/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.8500 - mse: 3.0603 - val_loss: 0.8492 - val_mse: 3.0485\n",
            "Epoch 18/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.8493 - mse: 3.0528 - val_loss: 0.8482 - val_mse: 3.0412\n",
            "Epoch 19/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.8482 - mse: 3.0455 - val_loss: 0.8470 - val_mse: 3.0336\n",
            "Epoch 20/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.8471 - mse: 3.0380 - val_loss: 0.8458 - val_mse: 3.0255\n",
            "Epoch 21/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.8458 - mse: 3.0299 - val_loss: 0.8444 - val_mse: 3.0165\n",
            "Epoch 22/500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.8445 - mse: 3.0209 - val_loss: 0.8429 - val_mse: 3.0062\n",
            "Epoch 23/500\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.8430 - mse: 3.0106 - val_loss: 0.8412 - val_mse: 2.9948\n",
            "Epoch 24/500\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.8412 - mse: 2.9992 - val_loss: 0.8390 - val_mse: 2.9819\n",
            "Epoch 25/500\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.8391 - mse: 2.9863 - val_loss: 0.8365 - val_mse: 2.9671\n",
            "Epoch 26/500\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.8366 - mse: 2.9716 - val_loss: 0.8338 - val_mse: 2.9502\n",
            "Epoch 27/500\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.8339 - mse: 2.9547 - val_loss: 0.8306 - val_mse: 2.9306\n",
            "Epoch 28/500\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.8308 - mse: 2.9352 - val_loss: 0.8267 - val_mse: 2.9078\n",
            "Epoch 29/500\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.8268 - mse: 2.9124 - val_loss: 0.8221 - val_mse: 2.8809\n",
            "Epoch 30/500\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.8223 - mse: 2.8856 - val_loss: 0.8167 - val_mse: 2.8484\n",
            "Epoch 31/500\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.8169 - mse: 2.8532 - val_loss: 0.8099 - val_mse: 2.8088\n",
            "Epoch 32/500\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.8101 - mse: 2.8136 - val_loss: 0.8012 - val_mse: 2.7595\n",
            "Epoch 33/500\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.8014 - mse: 2.7644 - val_loss: 0.7901 - val_mse: 2.6979\n",
            "Epoch 34/500\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.7904 - mse: 2.7030 - val_loss: 0.7762 - val_mse: 2.6220\n",
            "Epoch 35/500\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.7764 - mse: 2.6273 - val_loss: 0.7616 - val_mse: 2.5302\n",
            "Epoch 36/500\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 0.7619 - mse: 2.5356 - val_loss: 0.7459 - val_mse: 2.4193\n",
            "Epoch 37/500\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.7462 - mse: 2.4249 - val_loss: 0.7351 - val_mse: 2.2921\n",
            "Epoch 38/500\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.7352 - mse: 2.2977 - val_loss: 0.7337 - val_mse: 2.1604\n",
            "Epoch 39/500\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.7336 - mse: 2.1658 - val_loss: 0.7315 - val_mse: 2.0509\n",
            "Epoch 40/500\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.7312 - mse: 2.0559 - val_loss: 0.7280 - val_mse: 1.9720\n",
            "Epoch 41/500\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.7278 - mse: 1.9763 - val_loss: 0.7195 - val_mse: 1.9086\n",
            "Epoch 42/500\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.7194 - mse: 1.9123 - val_loss: 0.7073 - val_mse: 1.8577\n",
            "Epoch 43/500\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.7073 - mse: 1.8610 - val_loss: 0.6940 - val_mse: 1.8070\n",
            "Epoch 44/500\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.6940 - mse: 1.8100 - val_loss: 0.6780 - val_mse: 1.7560\n",
            "Epoch 45/500\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.6781 - mse: 1.7586 - val_loss: 0.6665 - val_mse: 1.7039\n",
            "Epoch 46/500\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 0.6659 - mse: 1.7063 - val_loss: 0.6528 - val_mse: 1.6787\n",
            "Epoch 47/500\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.6528 - mse: 1.6816 - val_loss: 0.6420 - val_mse: 1.6717\n",
            "Epoch 48/500\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.6420 - mse: 1.6752 - val_loss: 0.6350 - val_mse: 1.6626\n",
            "Epoch 49/500\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.6352 - mse: 1.6665 - val_loss: 0.6272 - val_mse: 1.6379\n",
            "Epoch 50/500\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.6273 - mse: 1.6418 - val_loss: 0.6212 - val_mse: 1.6051\n",
            "Epoch 51/500\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.6212 - mse: 1.6088 - val_loss: 0.6161 - val_mse: 1.5700\n",
            "Epoch 52/500\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.6163 - mse: 1.5734 - val_loss: 0.6110 - val_mse: 1.5307\n",
            "Epoch 53/500\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.6104 - mse: 1.5335 - val_loss: 0.6089 - val_mse: 1.5075\n",
            "Epoch 54/500\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.6082 - mse: 1.5100 - val_loss: 0.6029 - val_mse: 1.5111\n",
            "Epoch 55/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6026 - mse: 1.5139 - val_loss: 0.5991 - val_mse: 1.5261\n",
            "Epoch 56/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5988 - mse: 1.5294 - val_loss: 0.5992 - val_mse: 1.5298\n",
            "Epoch 57/500\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.5990 - mse: 1.5332 - val_loss: 0.5967 - val_mse: 1.5150\n",
            "Epoch 58/500\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.5963 - mse: 1.5183 - val_loss: 0.5907 - val_mse: 1.4870\n",
            "Epoch 59/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5905 - mse: 1.4899 - val_loss: 0.5864 - val_mse: 1.4442\n",
            "Epoch 60/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.5863 - mse: 1.4465 - val_loss: 0.5832 - val_mse: 1.4000\n",
            "Epoch 61/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5824 - mse: 1.4016 - val_loss: 0.5777 - val_mse: 1.3705\n",
            "Epoch 62/500\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.5769 - mse: 1.3721 - val_loss: 0.5704 - val_mse: 1.3587\n",
            "Epoch 63/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5702 - mse: 1.3611 - val_loss: 0.5678 - val_mse: 1.3476\n",
            "Epoch 64/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5674 - mse: 1.3504 - val_loss: 0.5633 - val_mse: 1.3301\n",
            "Epoch 65/500\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.5630 - mse: 1.3332 - val_loss: 0.5591 - val_mse: 1.3077\n",
            "Epoch 66/500\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.5588 - mse: 1.3110 - val_loss: 0.5539 - val_mse: 1.2758\n",
            "Epoch 67/500\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.5535 - mse: 1.2791 - val_loss: 0.5504 - val_mse: 1.2378\n",
            "Epoch 68/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.5500 - mse: 1.2409 - val_loss: 0.5463 - val_mse: 1.2025\n",
            "Epoch 69/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5459 - mse: 1.2055 - val_loss: 0.5404 - val_mse: 1.1670\n",
            "Epoch 70/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5401 - mse: 1.1699 - val_loss: 0.5333 - val_mse: 1.1278\n",
            "Epoch 71/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5329 - mse: 1.1305 - val_loss: 0.5270 - val_mse: 1.0931\n",
            "Epoch 72/500\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.5266 - mse: 1.0957 - val_loss: 0.5196 - val_mse: 1.0533\n",
            "Epoch 73/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.5194 - mse: 1.0557 - val_loss: 0.5110 - val_mse: 1.0064\n",
            "Epoch 74/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.5108 - mse: 1.0082 - val_loss: 0.5019 - val_mse: 0.9594\n",
            "Epoch 75/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5014 - mse: 0.9603 - val_loss: 0.4943 - val_mse: 0.9242\n",
            "Epoch 76/500\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.4939 - mse: 0.9242 - val_loss: 0.4857 - val_mse: 0.8973\n",
            "Epoch 77/500\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.4855 - mse: 0.8964 - val_loss: 0.4766 - val_mse: 0.8767\n",
            "Epoch 78/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.4764 - mse: 0.8745 - val_loss: 0.4745 - val_mse: 0.8652\n",
            "Epoch 79/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.4727 - mse: 0.8622 - val_loss: 0.4659 - val_mse: 0.8711\n",
            "Epoch 80/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.4666 - mse: 0.8707 - val_loss: 0.4559 - val_mse: 0.8462\n",
            "Epoch 81/500\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.4563 - mse: 0.8453 - val_loss: 0.4555 - val_mse: 0.8145\n",
            "Epoch 82/500\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.4538 - mse: 0.8115 - val_loss: 0.4429 - val_mse: 0.8009\n",
            "Epoch 83/500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.4410 - mse: 0.7989 - val_loss: 0.4431 - val_mse: 0.8105\n",
            "Epoch 84/500\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.4444 - mse: 0.8104 - val_loss: 0.4329 - val_mse: 0.7814\n",
            "Epoch 85/500\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.4340 - mse: 0.7802 - val_loss: 0.4313 - val_mse: 0.7566\n",
            "Epoch 86/500\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.4297 - mse: 0.7525 - val_loss: 0.4179 - val_mse: 0.7464\n",
            "Epoch 87/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.4162 - mse: 0.7423 - val_loss: 0.4067 - val_mse: 0.7477\n",
            "Epoch 88/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.4081 - mse: 0.7458 - val_loss: 0.3985 - val_mse: 0.7367\n",
            "Epoch 89/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.3987 - mse: 0.7339 - val_loss: 0.4016 - val_mse: 0.7302\n",
            "Epoch 90/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.3977 - mse: 0.7247 - val_loss: 0.3856 - val_mse: 0.7192\n",
            "Epoch 91/500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.3871 - mse: 0.7163 - val_loss: 0.3804 - val_mse: 0.7070\n",
            "Epoch 92/500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.3812 - mse: 0.7039 - val_loss: 0.3847 - val_mse: 0.6956\n",
            "Epoch 93/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.3808 - mse: 0.6905 - val_loss: 0.3712 - val_mse: 0.6883\n",
            "Epoch 94/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.3729 - mse: 0.6860 - val_loss: 0.3664 - val_mse: 0.6750\n",
            "Epoch 95/500\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.3674 - mse: 0.6724 - val_loss: 0.3708 - val_mse: 0.6641\n",
            "Epoch 96/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.3670 - mse: 0.6591 - val_loss: 0.3587 - val_mse: 0.6597\n",
            "Epoch 97/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.3590 - mse: 0.6567 - val_loss: 0.3606 - val_mse: 0.6599\n",
            "Epoch 98/500\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.3613 - mse: 0.6569 - val_loss: 0.3611 - val_mse: 0.6580\n",
            "Epoch 99/500\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.3576 - mse: 0.6533 - val_loss: 0.3523 - val_mse: 0.6594\n",
            "Epoch 100/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.3539 - mse: 0.6565 - val_loss: 0.3516 - val_mse: 0.6583\n",
            "Epoch 101/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.3522 - mse: 0.6549 - val_loss: 0.3541 - val_mse: 0.6526\n",
            "Epoch 102/500\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.3518 - mse: 0.6484 - val_loss: 0.3471 - val_mse: 0.6476\n",
            "Epoch 103/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.3494 - mse: 0.6447 - val_loss: 0.3489 - val_mse: 0.6404\n",
            "Epoch 104/500\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.3489 - mse: 0.6367 - val_loss: 0.3509 - val_mse: 0.6369\n",
            "Epoch 105/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.3488 - mse: 0.6327 - val_loss: 0.3443 - val_mse: 0.6374\n",
            "Epoch 106/500\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.3471 - mse: 0.6347 - val_loss: 0.3451 - val_mse: 0.6329\n",
            "Epoch 107/500\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.3425 - mse: 0.6288 - val_loss: 0.3399 - val_mse: 0.6342\n",
            "Epoch 108/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.3400 - mse: 0.6308 - val_loss: 0.3383 - val_mse: 0.6353\n",
            "Epoch 109/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.3399 - mse: 0.6322 - val_loss: 0.3406 - val_mse: 0.6284\n",
            "Epoch 110/500\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.3379 - mse: 0.6241 - val_loss: 0.3345 - val_mse: 0.6226\n",
            "Epoch 111/500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.3357 - mse: 0.6194 - val_loss: 0.3348 - val_mse: 0.6185\n",
            "Epoch 112/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.3347 - mse: 0.6149 - val_loss: 0.3401 - val_mse: 0.6193\n",
            "Epoch 113/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.3363 - mse: 0.6147 - val_loss: 0.3333 - val_mse: 0.6244\n",
            "Epoch 114/500\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.3361 - mse: 0.6219 - val_loss: 0.3295 - val_mse: 0.6211\n",
            "Epoch 115/500\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.3302 - mse: 0.6175 - val_loss: 0.3372 - val_mse: 0.6197\n",
            "Epoch 116/500\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.3337 - mse: 0.6151 - val_loss: 0.3308 - val_mse: 0.6196\n",
            "Epoch 117/500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.3337 - mse: 0.6170 - val_loss: 0.3254 - val_mse: 0.6136\n",
            "Epoch 118/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.3265 - mse: 0.6102 - val_loss: 0.3353 - val_mse: 0.6139\n",
            "Epoch 119/500\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.3315 - mse: 0.6091 - val_loss: 0.3274 - val_mse: 0.6163\n",
            "Epoch 120/500\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.3301 - mse: 0.6137 - val_loss: 0.3237 - val_mse: 0.6118\n",
            "Epoch 121/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.3256 - mse: 0.6086 - val_loss: 0.3333 - val_mse: 0.6109\n",
            "Epoch 122/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.3295 - mse: 0.6060 - val_loss: 0.3218 - val_mse: 0.6105\n",
            "Epoch 123/500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.3239 - mse: 0.6075 - val_loss: 0.3210 - val_mse: 0.6097\n",
            "Epoch 124/500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.3228 - mse: 0.6065 - val_loss: 0.3304 - val_mse: 0.6111\n",
            "Epoch 125/500\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.3270 - mse: 0.6063 - val_loss: 0.3185 - val_mse: 0.6076\n",
            "Epoch 126/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.3202 - mse: 0.6042 - val_loss: 0.3175 - val_mse: 0.6040\n",
            "Epoch 127/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.3200 - mse: 0.6010 - val_loss: 0.3266 - val_mse: 0.6018\n",
            "Epoch 128/500\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.3228 - mse: 0.5970 - val_loss: 0.3147 - val_mse: 0.6006\n",
            "Epoch 129/500\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.3159 - mse: 0.5971 - val_loss: 0.3150 - val_mse: 0.6028\n",
            "Epoch 130/500\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.3179 - mse: 0.6000 - val_loss: 0.3152 - val_mse: 0.5983\n",
            "Epoch 131/500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.3128 - mse: 0.5942 - val_loss: 0.3137 - val_mse: 0.5950\n",
            "Epoch 132/500\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.3121 - mse: 0.5910 - val_loss: 0.3102 - val_mse: 0.5957\n",
            "Epoch 133/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.3126 - mse: 0.5926 - val_loss: 0.3090 - val_mse: 0.5944\n",
            "Epoch 134/500\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.3090 - mse: 0.5907 - val_loss: 0.3117 - val_mse: 0.5920\n",
            "Epoch 135/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.3098 - mse: 0.5879 - val_loss: 0.3061 - val_mse: 0.5886\n",
            "Epoch 136/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.3080 - mse: 0.5853 - val_loss: 0.3070 - val_mse: 0.5842\n",
            "Epoch 137/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.3069 - mse: 0.5805 - val_loss: 0.3079 - val_mse: 0.5811\n",
            "Epoch 138/500\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.3059 - mse: 0.5770 - val_loss: 0.3020 - val_mse: 0.5819\n",
            "Epoch 139/500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.3036 - mse: 0.5785 - val_loss: 0.3027 - val_mse: 0.5801\n",
            "Epoch 140/500\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.3018 - mse: 0.5763 - val_loss: 0.3033 - val_mse: 0.5760\n",
            "Epoch 141/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.3013 - mse: 0.5720 - val_loss: 0.2984 - val_mse: 0.5728\n",
            "Epoch 142/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.3008 - mse: 0.5696 - val_loss: 0.3005 - val_mse: 0.5696\n",
            "Epoch 143/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.2985 - mse: 0.5656 - val_loss: 0.2972 - val_mse: 0.5663\n",
            "Epoch 144/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.2971 - mse: 0.5627 - val_loss: 0.2953 - val_mse: 0.5621\n",
            "Epoch 145/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.2955 - mse: 0.5585 - val_loss: 0.2981 - val_mse: 0.5607\n",
            "Epoch 146/500\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.2958 - mse: 0.5567 - val_loss: 0.2930 - val_mse: 0.5601\n",
            "Epoch 147/500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.2950 - mse: 0.5570 - val_loss: 0.2948 - val_mse: 0.5536\n",
            "Epoch 148/500\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.2927 - mse: 0.5496 - val_loss: 0.2912 - val_mse: 0.5481\n",
            "Epoch 149/500\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.2904 - mse: 0.5443 - val_loss: 0.2900 - val_mse: 0.5450\n",
            "Epoch 150/500\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.2894 - mse: 0.5413 - val_loss: 0.2895 - val_mse: 0.5450\n",
            "Epoch 151/500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.2879 - mse: 0.5411 - val_loss: 0.2868 - val_mse: 0.5428\n",
            "Epoch 152/500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.2874 - mse: 0.5394 - val_loss: 0.2867 - val_mse: 0.5374\n",
            "Epoch 153/500\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.2848 - mse: 0.5335 - val_loss: 0.2854 - val_mse: 0.5338\n",
            "Epoch 154/500\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.2847 - mse: 0.5302 - val_loss: 0.2836 - val_mse: 0.5330\n",
            "Epoch 155/500\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.2837 - mse: 0.5296 - val_loss: 0.2836 - val_mse: 0.5292\n",
            "Epoch 156/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.2823 - mse: 0.5257 - val_loss: 0.2827 - val_mse: 0.5238\n",
            "Epoch 157/500\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.2817 - mse: 0.5202 - val_loss: 0.2804 - val_mse: 0.5189\n",
            "Epoch 158/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.2795 - mse: 0.5153 - val_loss: 0.2794 - val_mse: 0.5160\n",
            "Epoch 159/500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.2784 - mse: 0.5125 - val_loss: 0.2796 - val_mse: 0.5119\n",
            "Epoch 160/500\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.2780 - mse: 0.5082 - val_loss: 0.2755 - val_mse: 0.5066\n",
            "Epoch 161/500\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.2744 - mse: 0.5031 - val_loss: 0.2735 - val_mse: 0.5021\n",
            "Epoch 162/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.2735 - mse: 0.4988 - val_loss: 0.2739 - val_mse: 0.4972\n",
            "Epoch 163/500\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.2724 - mse: 0.4936 - val_loss: 0.2704 - val_mse: 0.4935\n",
            "Epoch 164/500\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.2698 - mse: 0.4901 - val_loss: 0.2680 - val_mse: 0.4894\n",
            "Epoch 165/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.2687 - mse: 0.4863 - val_loss: 0.2701 - val_mse: 0.4808\n",
            "Epoch 166/500\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.2673 - mse: 0.4770 - val_loss: 0.2660 - val_mse: 0.4766\n",
            "Epoch 167/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.2669 - mse: 0.4738 - val_loss: 0.2698 - val_mse: 0.4689\n",
            "Epoch 168/500\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.2666 - mse: 0.4650 - val_loss: 0.2623 - val_mse: 0.4712\n",
            "Epoch 169/500\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.2634 - mse: 0.4684 - val_loss: 0.2586 - val_mse: 0.4641\n",
            "Epoch 170/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.2573 - mse: 0.4606 - val_loss: 0.2590 - val_mse: 0.4580\n",
            "Epoch 171/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.2568 - mse: 0.4543 - val_loss: 0.2587 - val_mse: 0.4578\n",
            "Epoch 172/500\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.2599 - mse: 0.4553 - val_loss: 0.2608 - val_mse: 0.4464\n",
            "Epoch 173/500\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.2577 - mse: 0.4423 - val_loss: 0.2516 - val_mse: 0.4437\n",
            "Epoch 174/500\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.2530 - mse: 0.4410 - val_loss: 0.2477 - val_mse: 0.4364\n",
            "Epoch 175/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.2478 - mse: 0.4332 - val_loss: 0.2510 - val_mse: 0.4310\n",
            "Epoch 176/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.2481 - mse: 0.4273 - val_loss: 0.2527 - val_mse: 0.4340\n",
            "Epoch 177/500\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.2535 - mse: 0.4317 - val_loss: 0.2493 - val_mse: 0.4234\n",
            "Epoch 178/500\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.2457 - mse: 0.4197 - val_loss: 0.2409 - val_mse: 0.4223\n",
            "Epoch 179/500\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.2403 - mse: 0.4193 - val_loss: 0.2405 - val_mse: 0.4180\n",
            "Epoch 180/500\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.2410 - mse: 0.4153 - val_loss: 0.2494 - val_mse: 0.4092\n",
            "Epoch 181/500\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.2448 - mse: 0.4051 - val_loss: 0.2463 - val_mse: 0.4082\n",
            "Epoch 182/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.2469 - mse: 0.4059 - val_loss: 0.2400 - val_mse: 0.3957\n",
            "Epoch 183/500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.2377 - mse: 0.3923 - val_loss: 0.2464 - val_mse: 0.3948\n",
            "Epoch 184/500\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.2418 - mse: 0.3909 - val_loss: 0.2460 - val_mse: 0.4008\n",
            "Epoch 185/500\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.2463 - mse: 0.3988 - val_loss: 0.2351 - val_mse: 0.3900\n",
            "Epoch 186/500\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.2339 - mse: 0.3871 - val_loss: 0.2515 - val_mse: 0.3869\n",
            "Epoch 187/500\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.2464 - mse: 0.3827 - val_loss: 0.2355 - val_mse: 0.3832\n",
            "Epoch 188/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.2360 - mse: 0.3811 - val_loss: 0.2325 - val_mse: 0.3735\n",
            "Epoch 189/500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.2313 - mse: 0.3710 - val_loss: 0.2441 - val_mse: 0.3654\n",
            "Epoch 190/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.2387 - mse: 0.3614 - val_loss: 0.2320 - val_mse: 0.3626\n",
            "Epoch 191/500\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.2311 - mse: 0.3602 - val_loss: 0.2285 - val_mse: 0.3568\n",
            "Epoch 192/500\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.2268 - mse: 0.3543 - val_loss: 0.2311 - val_mse: 0.3549\n",
            "Epoch 193/500\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.2269 - mse: 0.3514 - val_loss: 0.2218 - val_mse: 0.3584\n",
            "Epoch 194/500\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.2213 - mse: 0.3560 - val_loss: 0.2210 - val_mse: 0.3544\n",
            "Epoch 195/500\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.2196 - mse: 0.3517 - val_loss: 0.2254 - val_mse: 0.3482\n",
            "Epoch 196/500\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.2212 - mse: 0.3449 - val_loss: 0.2219 - val_mse: 0.3456\n",
            "Epoch 197/500\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.2220 - mse: 0.3434 - val_loss: 0.2193 - val_mse: 0.3352\n",
            "Epoch 198/500\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.2160 - mse: 0.3321 - val_loss: 0.2191 - val_mse: 0.3302\n",
            "Epoch 199/500\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.2155 - mse: 0.3271 - val_loss: 0.2213 - val_mse: 0.3351\n",
            "Epoch 200/500\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.2211 - mse: 0.3332 - val_loss: 0.2169 - val_mse: 0.3264\n",
            "Epoch 201/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.2128 - mse: 0.3232 - val_loss: 0.2101 - val_mse: 0.3241\n",
            "Epoch 202/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.2086 - mse: 0.3214 - val_loss: 0.2091 - val_mse: 0.3228\n",
            "Epoch 203/500\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.2089 - mse: 0.3202 - val_loss: 0.2121 - val_mse: 0.3177\n",
            "Epoch 204/500\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.2084 - mse: 0.3147 - val_loss: 0.2125 - val_mse: 0.3163\n",
            "Epoch 205/500\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.2120 - mse: 0.3142 - val_loss: 0.2090 - val_mse: 0.3063\n",
            "Epoch 206/500\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.2050 - mse: 0.3032 - val_loss: 0.2046 - val_mse: 0.3027\n",
            "Epoch 207/500\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.2027 - mse: 0.3000 - val_loss: 0.2052 - val_mse: 0.2967\n",
            "Epoch 208/500\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.2032 - mse: 0.2940 - val_loss: 0.2024 - val_mse: 0.2920\n",
            "Epoch 209/500\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.1995 - mse: 0.2892 - val_loss: 0.1998 - val_mse: 0.2924\n",
            "Epoch 210/500\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.1997 - mse: 0.2899 - val_loss: 0.2022 - val_mse: 0.2886\n",
            "Epoch 211/500\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.1994 - mse: 0.2857 - val_loss: 0.2006 - val_mse: 0.2867\n",
            "Epoch 212/500\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.2002 - mse: 0.2845 - val_loss: 0.2041 - val_mse: 0.2806\n",
            "Epoch 213/500\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.2003 - mse: 0.2776 - val_loss: 0.1966 - val_mse: 0.2803\n",
            "Epoch 214/500\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.1959 - mse: 0.2780 - val_loss: 0.1928 - val_mse: 0.2724\n",
            "Epoch 215/500\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.1914 - mse: 0.2698 - val_loss: 0.1948 - val_mse: 0.2606\n",
            "Epoch 216/500\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.1920 - mse: 0.2578 - val_loss: 0.1923 - val_mse: 0.2559\n",
            "Epoch 217/500\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.1910 - mse: 0.2535 - val_loss: 0.1929 - val_mse: 0.2541\n",
            "Epoch 218/500\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.1895 - mse: 0.2512 - val_loss: 0.1904 - val_mse: 0.2565\n",
            "Epoch 219/500\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.1905 - mse: 0.2544 - val_loss: 0.1932 - val_mse: 0.2497\n",
            "Epoch 220/500\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.1891 - mse: 0.2469 - val_loss: 0.1839 - val_mse: 0.2503\n",
            "Epoch 221/500\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.1836 - mse: 0.2481 - val_loss: 0.1878 - val_mse: 0.2476\n",
            "Epoch 222/500\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.1852 - mse: 0.2449 - val_loss: 0.1810 - val_mse: 0.2460\n",
            "Epoch 223/500\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.1804 - mse: 0.2437 - val_loss: 0.1839 - val_mse: 0.2378\n",
            "Epoch 224/500\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.1804 - mse: 0.2350 - val_loss: 0.1840 - val_mse: 0.2342\n",
            "Epoch 225/500\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.1825 - mse: 0.2318 - val_loss: 0.1799 - val_mse: 0.2295\n",
            "Epoch 226/500\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.1764 - mse: 0.2267 - val_loss: 0.1782 - val_mse: 0.2280\n",
            "Epoch 227/500\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.1777 - mse: 0.2257 - val_loss: 0.1811 - val_mse: 0.2203\n",
            "Epoch 228/500\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.1771 - mse: 0.2174 - val_loss: 0.1765 - val_mse: 0.2189\n",
            "Epoch 229/500\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.1761 - mse: 0.2167 - val_loss: 0.1814 - val_mse: 0.2148\n",
            "Epoch 230/500\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.1771 - mse: 0.2118 - val_loss: 0.1743 - val_mse: 0.2155\n",
            "Epoch 231/500\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.1734 - mse: 0.2131 - val_loss: 0.1741 - val_mse: 0.2101\n",
            "Epoch 232/500\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.1701 - mse: 0.2073 - val_loss: 0.1718 - val_mse: 0.2091\n",
            "Epoch 233/500\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 0.1700 - mse: 0.2066 - val_loss: 0.1750 - val_mse: 0.2083\n",
            "Epoch 234/500\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.1707 - mse: 0.2053 - val_loss: 0.1708 - val_mse: 0.2091\n",
            "Epoch 235/500\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.1700 - mse: 0.2067 - val_loss: 0.1725 - val_mse: 0.2016\n",
            "Epoch 236/500\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.1681 - mse: 0.1986 - val_loss: 0.1672 - val_mse: 0.1988\n",
            "Epoch 237/500\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 0.1662 - mse: 0.1963 - val_loss: 0.1670 - val_mse: 0.1945\n",
            "Epoch 238/500\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.1629 - mse: 0.1916 - val_loss: 0.1635 - val_mse: 0.1946\n",
            "Epoch 239/500\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 0.1627 - mse: 0.1920 - val_loss: 0.1689 - val_mse: 0.1887\n",
            "Epoch 240/500\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 0.1644 - mse: 0.1855 - val_loss: 0.1698 - val_mse: 0.1891\n",
            "Epoch 241/500\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.1684 - mse: 0.1868 - val_loss: 0.1680 - val_mse: 0.1820\n",
            "Epoch 242/500\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.1638 - mse: 0.1789 - val_loss: 0.1604 - val_mse: 0.1797\n",
            "Epoch 243/500\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.1584 - mse: 0.1770 - val_loss: 0.1612 - val_mse: 0.1782\n",
            "Epoch 244/500\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.1585 - mse: 0.1754 - val_loss: 0.1589 - val_mse: 0.1755\n",
            "Epoch 245/500\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.1557 - mse: 0.1726 - val_loss: 0.1584 - val_mse: 0.1734\n",
            "Epoch 246/500\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.1559 - mse: 0.1705 - val_loss: 0.1602 - val_mse: 0.1714\n",
            "Epoch 247/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.1569 - mse: 0.1684 - val_loss: 0.1593 - val_mse: 0.1685\n",
            "Epoch 248/500\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.1585 - mse: 0.1659 - val_loss: 0.1689 - val_mse: 0.1652\n",
            "Epoch 249/500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.1641 - mse: 0.1616 - val_loss: 0.1569 - val_mse: 0.1625\n",
            "Epoch 250/500\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.1556 - mse: 0.1599 - val_loss: 0.1561 - val_mse: 0.1599\n",
            "Epoch 251/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.1530 - mse: 0.1570 - val_loss: 0.1575 - val_mse: 0.1553\n",
            "Epoch 252/500\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.1535 - mse: 0.1521 - val_loss: 0.1569 - val_mse: 0.1540\n",
            "Epoch 253/500\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.1555 - mse: 0.1514 - val_loss: 0.1591 - val_mse: 0.1514\n",
            "Epoch 254/500\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.1552 - mse: 0.1481 - val_loss: 0.1538 - val_mse: 0.1502\n",
            "Epoch 255/500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.1508 - mse: 0.1472 - val_loss: 0.1536 - val_mse: 0.1495\n",
            "Epoch 256/500\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.1522 - mse: 0.1470 - val_loss: 0.1615 - val_mse: 0.1436\n",
            "Epoch 257/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.1567 - mse: 0.1401 - val_loss: 0.1508 - val_mse: 0.1408\n",
            "Epoch 258/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.1491 - mse: 0.1379 - val_loss: 0.1487 - val_mse: 0.1389\n",
            "Epoch 259/500\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.1463 - mse: 0.1359 - val_loss: 0.1521 - val_mse: 0.1372\n",
            "Epoch 260/500\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.1481 - mse: 0.1337 - val_loss: 0.1480 - val_mse: 0.1351\n",
            "Epoch 261/500\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.1467 - mse: 0.1323 - val_loss: 0.1488 - val_mse: 0.1322\n",
            "Epoch 262/500\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.1453 - mse: 0.1290 - val_loss: 0.1448 - val_mse: 0.1311\n",
            "Epoch 263/500\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.1423 - mse: 0.1280 - val_loss: 0.1407 - val_mse: 0.1282\n",
            "Epoch 264/500\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.1391 - mse: 0.1252 - val_loss: 0.1456 - val_mse: 0.1256\n",
            "Epoch 265/500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.1418 - mse: 0.1220 - val_loss: 0.1446 - val_mse: 0.1246\n",
            "Epoch 266/500\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.1432 - mse: 0.1218 - val_loss: 0.1394 - val_mse: 0.1215\n",
            "Epoch 267/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.1364 - mse: 0.1183 - val_loss: 0.1353 - val_mse: 0.1195\n",
            "Epoch 268/500\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.1332 - mse: 0.1164 - val_loss: 0.1369 - val_mse: 0.1169\n",
            "Epoch 269/500\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.1352 - mse: 0.1138 - val_loss: 0.1392 - val_mse: 0.1153\n",
            "Epoch 270/500\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.1358 - mse: 0.1119 - val_loss: 0.1377 - val_mse: 0.1151\n",
            "Epoch 271/500\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.1366 - mse: 0.1122 - val_loss: 0.1368 - val_mse: 0.1120\n",
            "Epoch 272/500\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.1334 - mse: 0.1085 - val_loss: 0.1331 - val_mse: 0.1101\n",
            "Epoch 273/500\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.1307 - mse: 0.1069 - val_loss: 0.1326 - val_mse: 0.1077\n",
            "Epoch 274/500\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.1308 - mse: 0.1045 - val_loss: 0.1339 - val_mse: 0.1055\n",
            "Epoch 275/500\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.1306 - mse: 0.1021 - val_loss: 0.1362 - val_mse: 0.1063\n",
            "Epoch 276/500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.1348 - mse: 0.1036 - val_loss: 0.1326 - val_mse: 0.1012\n",
            "Epoch 277/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.1294 - mse: 0.0978 - val_loss: 0.1311 - val_mse: 0.0978\n",
            "Epoch 278/500\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.1296 - mse: 0.0946 - val_loss: 0.1300 - val_mse: 0.0957\n",
            "Epoch 279/500\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.1268 - mse: 0.0923 - val_loss: 0.1266 - val_mse: 0.0958\n",
            "Epoch 280/500\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.1252 - mse: 0.0927 - val_loss: 0.1270 - val_mse: 0.0937\n",
            "Epoch 281/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.1243 - mse: 0.0904 - val_loss: 0.1250 - val_mse: 0.0913\n",
            "Epoch 282/500\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.1232 - mse: 0.0881 - val_loss: 0.1243 - val_mse: 0.0892\n",
            "Epoch 283/500\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.1221 - mse: 0.0859 - val_loss: 0.1257 - val_mse: 0.0870\n",
            "Epoch 284/500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.1228 - mse: 0.0837 - val_loss: 0.1221 - val_mse: 0.0847\n",
            "Epoch 285/500\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.1202 - mse: 0.0814 - val_loss: 0.1213 - val_mse: 0.0828\n",
            "Epoch 286/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.1183 - mse: 0.0794 - val_loss: 0.1176 - val_mse: 0.0823\n",
            "Epoch 287/500\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.1165 - mse: 0.0791 - val_loss: 0.1265 - val_mse: 0.0819\n",
            "Epoch 288/500\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.1230 - mse: 0.0783 - val_loss: 0.1231 - val_mse: 0.0803\n",
            "Epoch 289/500\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.1218 - mse: 0.0772 - val_loss: 0.1195 - val_mse: 0.0773\n",
            "Epoch 290/500\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.1161 - mse: 0.0736 - val_loss: 0.1143 - val_mse: 0.0755\n",
            "Epoch 291/500\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.1121 - mse: 0.0722 - val_loss: 0.1143 - val_mse: 0.0747\n",
            "Epoch 292/500\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.1134 - mse: 0.0715 - val_loss: 0.1189 - val_mse: 0.0743\n",
            "Epoch 293/500\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.1155 - mse: 0.0707 - val_loss: 0.1269 - val_mse: 0.0749\n",
            "Epoch 294/500\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.1250 - mse: 0.0720 - val_loss: 0.1151 - val_mse: 0.0703\n",
            "Epoch 295/500\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.1119 - mse: 0.0667 - val_loss: 0.1211 - val_mse: 0.0717\n",
            "Epoch 296/500\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.1179 - mse: 0.0681 - val_loss: 0.1225 - val_mse: 0.0720\n",
            "Epoch 297/500\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.1207 - mse: 0.0691 - val_loss: 0.1105 - val_mse: 0.0673\n",
            "Epoch 298/500\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.1077 - mse: 0.0639 - val_loss: 0.1217 - val_mse: 0.0699\n",
            "Epoch 299/500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.1178 - mse: 0.0661 - val_loss: 0.1177 - val_mse: 0.0678\n",
            "Epoch 300/500\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.1161 - mse: 0.0649 - val_loss: 0.1082 - val_mse: 0.0638\n",
            "Epoch 301/500\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.1061 - mse: 0.0605 - val_loss: 0.1144 - val_mse: 0.0642\n",
            "Epoch 302/500\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.1108 - mse: 0.0606 - val_loss: 0.1181 - val_mse: 0.0652\n",
            "Epoch 303/500\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.1162 - mse: 0.0624 - val_loss: 0.1042 - val_mse: 0.0604\n",
            "Epoch 304/500\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.1023 - mse: 0.0572 - val_loss: 0.1224 - val_mse: 0.0640\n",
            "Epoch 305/500\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.1181 - mse: 0.0602 - val_loss: 0.1087 - val_mse: 0.0597\n",
            "Epoch 306/500\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.1070 - mse: 0.0567 - val_loss: 0.1023 - val_mse: 0.0574\n",
            "Epoch 307/500\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.1014 - mse: 0.0543 - val_loss: 0.1188 - val_mse: 0.0607\n",
            "Epoch 308/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.1143 - mse: 0.0569 - val_loss: 0.1029 - val_mse: 0.0550\n",
            "Epoch 309/500\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.1018 - mse: 0.0519 - val_loss: 0.1013 - val_mse: 0.0540\n",
            "Epoch 310/500\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.1005 - mse: 0.0509 - val_loss: 0.1158 - val_mse: 0.0569\n",
            "Epoch 311/500\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.1115 - mse: 0.0531 - val_loss: 0.0994 - val_mse: 0.0520\n",
            "Epoch 312/500\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.0977 - mse: 0.0488 - val_loss: 0.1009 - val_mse: 0.0520\n",
            "Epoch 313/500\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0997 - mse: 0.0489 - val_loss: 0.1103 - val_mse: 0.0534\n",
            "Epoch 314/500\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.1062 - mse: 0.0497 - val_loss: 0.0968 - val_mse: 0.0499\n",
            "Epoch 315/500\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.0951 - mse: 0.0467 - val_loss: 0.0946 - val_mse: 0.0492\n",
            "Epoch 316/500\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0927 - mse: 0.0460 - val_loss: 0.1014 - val_mse: 0.0498\n",
            "Epoch 317/500\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.0981 - mse: 0.0462 - val_loss: 0.0961 - val_mse: 0.0480\n",
            "Epoch 318/500\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0950 - mse: 0.0449 - val_loss: 0.0931 - val_mse: 0.0471\n",
            "Epoch 319/500\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0906 - mse: 0.0437 - val_loss: 0.0916 - val_mse: 0.0465\n",
            "Epoch 320/500\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.0893 - mse: 0.0432 - val_loss: 0.0910 - val_mse: 0.0463\n",
            "Epoch 321/500\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0898 - mse: 0.0432 - val_loss: 0.0951 - val_mse: 0.0470\n",
            "Epoch 322/500\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0919 - mse: 0.0434 - val_loss: 0.0927 - val_mse: 0.0456\n",
            "Epoch 323/500\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0916 - mse: 0.0425 - val_loss: 0.0907 - val_mse: 0.0447\n",
            "Epoch 324/500\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.0881 - mse: 0.0413 - val_loss: 0.0861 - val_mse: 0.0434\n",
            "Epoch 325/500\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0841 - mse: 0.0402 - val_loss: 0.0882 - val_mse: 0.0434\n",
            "Epoch 326/500\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.0874 - mse: 0.0404 - val_loss: 0.0945 - val_mse: 0.0445\n",
            "Epoch 327/500\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.0910 - mse: 0.0410 - val_loss: 0.0904 - val_mse: 0.0433\n",
            "Epoch 328/500\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0894 - mse: 0.0403 - val_loss: 0.0881 - val_mse: 0.0427\n",
            "Epoch 329/500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0856 - mse: 0.0393 - val_loss: 0.0816 - val_mse: 0.0414\n",
            "Epoch 330/500\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0803 - mse: 0.0382 - val_loss: 0.0824 - val_mse: 0.0411\n",
            "Epoch 331/500\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0814 - mse: 0.0379 - val_loss: 0.0826 - val_mse: 0.0409\n",
            "Epoch 332/500\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0802 - mse: 0.0375 - val_loss: 0.0862 - val_mse: 0.0411\n",
            "Epoch 333/500\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0852 - mse: 0.0381 - val_loss: 0.0860 - val_mse: 0.0406\n",
            "Epoch 334/500\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0831 - mse: 0.0372 - val_loss: 0.0814 - val_mse: 0.0397\n",
            "Epoch 335/500\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0807 - mse: 0.0367 - val_loss: 0.0802 - val_mse: 0.0388\n",
            "Epoch 336/500\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0783 - mse: 0.0355 - val_loss: 0.0759 - val_mse: 0.0381\n",
            "Epoch 337/500\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.0749 - mse: 0.0349 - val_loss: 0.0777 - val_mse: 0.0378\n",
            "Epoch 338/500\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0759 - mse: 0.0346 - val_loss: 0.0767 - val_mse: 0.0374\n",
            "Epoch 339/500\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0748 - mse: 0.0342 - val_loss: 0.0756 - val_mse: 0.0368\n",
            "Epoch 340/500\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0739 - mse: 0.0337 - val_loss: 0.0758 - val_mse: 0.0364\n",
            "Epoch 341/500\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0735 - mse: 0.0332 - val_loss: 0.0766 - val_mse: 0.0365\n",
            "Epoch 342/500\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0757 - mse: 0.0335 - val_loss: 0.0838 - val_mse: 0.0375\n",
            "Epoch 343/500\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0806 - mse: 0.0341 - val_loss: 0.0788 - val_mse: 0.0361\n",
            "Epoch 344/500\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.0775 - mse: 0.0332 - val_loss: 0.0750 - val_mse: 0.0344\n",
            "Epoch 345/500\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0730 - mse: 0.0312 - val_loss: 0.0721 - val_mse: 0.0339\n",
            "Epoch 346/500\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0710 - mse: 0.0309 - val_loss: 0.0723 - val_mse: 0.0337\n",
            "Epoch 347/500\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0713 - mse: 0.0308 - val_loss: 0.0782 - val_mse: 0.0341\n",
            "Epoch 348/500\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0755 - mse: 0.0308 - val_loss: 0.0809 - val_mse: 0.0353\n",
            "Epoch 349/500\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0792 - mse: 0.0326 - val_loss: 0.0723 - val_mse: 0.0325\n",
            "Epoch 350/500\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0702 - mse: 0.0294 - val_loss: 0.0700 - val_mse: 0.0319\n",
            "Epoch 351/500\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0683 - mse: 0.0289 - val_loss: 0.0742 - val_mse: 0.0326\n",
            "Epoch 352/500\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0729 - mse: 0.0298 - val_loss: 0.0818 - val_mse: 0.0332\n",
            "Epoch 353/500\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0781 - mse: 0.0299 - val_loss: 0.0721 - val_mse: 0.0314\n",
            "Epoch 354/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0712 - mse: 0.0286 - val_loss: 0.0664 - val_mse: 0.0301\n",
            "Epoch 355/500\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.0656 - mse: 0.0272 - val_loss: 0.0773 - val_mse: 0.0310\n",
            "Epoch 356/500\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.0739 - mse: 0.0278 - val_loss: 0.0731 - val_mse: 0.0307\n",
            "Epoch 357/500\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.0716 - mse: 0.0280 - val_loss: 0.0668 - val_mse: 0.0287\n",
            "Epoch 358/500\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0652 - mse: 0.0258 - val_loss: 0.0652 - val_mse: 0.0281\n",
            "Epoch 359/500\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0634 - mse: 0.0252 - val_loss: 0.0705 - val_mse: 0.0292\n",
            "Epoch 360/500\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0691 - mse: 0.0267 - val_loss: 0.0731 - val_mse: 0.0281\n",
            "Epoch 361/500\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0699 - mse: 0.0251 - val_loss: 0.0635 - val_mse: 0.0267\n",
            "Epoch 362/500\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0626 - mse: 0.0241 - val_loss: 0.0612 - val_mse: 0.0258\n",
            "Epoch 363/500\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0600 - mse: 0.0230 - val_loss: 0.0629 - val_mse: 0.0254\n",
            "Epoch 364/500\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0610 - mse: 0.0226 - val_loss: 0.0669 - val_mse: 0.0260\n",
            "Epoch 365/500\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.0657 - mse: 0.0236 - val_loss: 0.0641 - val_mse: 0.0246\n",
            "Epoch 366/500\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0614 - mse: 0.0219 - val_loss: 0.0608 - val_mse: 0.0238\n",
            "Epoch 367/500\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0597 - mse: 0.0213 - val_loss: 0.0613 - val_mse: 0.0236\n",
            "Epoch 368/500\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0597 - mse: 0.0210 - val_loss: 0.0606 - val_mse: 0.0227\n",
            "Epoch 369/500\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0586 - mse: 0.0200 - val_loss: 0.0616 - val_mse: 0.0227\n",
            "Epoch 370/500\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.0605 - mse: 0.0203 - val_loss: 0.0626 - val_mse: 0.0223\n",
            "Epoch 371/500\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0603 - mse: 0.0197 - val_loss: 0.0612 - val_mse: 0.0223\n",
            "Epoch 372/500\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0603 - mse: 0.0200 - val_loss: 0.0594 - val_mse: 0.0209\n",
            "Epoch 373/500\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.0572 - mse: 0.0184 - val_loss: 0.0545 - val_mse: 0.0199\n",
            "Epoch 374/500\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.0530 - mse: 0.0175 - val_loss: 0.0564 - val_mse: 0.0199\n",
            "Epoch 375/500\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0552 - mse: 0.0176 - val_loss: 0.0572 - val_mse: 0.0193\n",
            "Epoch 376/500\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.0553 - mse: 0.0169 - val_loss: 0.0527 - val_mse: 0.0187\n",
            "Epoch 377/500\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0520 - mse: 0.0166 - val_loss: 0.0518 - val_mse: 0.0179\n",
            "Epoch 378/500\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0502 - mse: 0.0157 - val_loss: 0.0522 - val_mse: 0.0174\n",
            "Epoch 379/500\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.0511 - mse: 0.0153 - val_loss: 0.0496 - val_mse: 0.0168\n",
            "Epoch 380/500\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.0488 - mse: 0.0148 - val_loss: 0.0512 - val_mse: 0.0162\n",
            "Epoch 381/500\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.0495 - mse: 0.0141 - val_loss: 0.0547 - val_mse: 0.0165\n",
            "Epoch 382/500\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.0534 - mse: 0.0147 - val_loss: 0.0557 - val_mse: 0.0159\n",
            "Epoch 383/500\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0531 - mse: 0.0138 - val_loss: 0.0543 - val_mse: 0.0155\n",
            "Epoch 384/500\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.0527 - mse: 0.0138 - val_loss: 0.0507 - val_mse: 0.0141\n",
            "Epoch 385/500\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0488 - mse: 0.0122 - val_loss: 0.0473 - val_mse: 0.0132\n",
            "Epoch 386/500\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0465 - mse: 0.0115 - val_loss: 0.0458 - val_mse: 0.0125\n",
            "Epoch 387/500\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0442 - mse: 0.0108 - val_loss: 0.0456 - val_mse: 0.0121\n",
            "Epoch 388/500\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0447 - mse: 0.0106 - val_loss: 0.0478 - val_mse: 0.0120\n",
            "Epoch 389/500\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.0450 - mse: 0.0103 - val_loss: 0.0489 - val_mse: 0.0120\n",
            "Epoch 390/500\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0477 - mse: 0.0106 - val_loss: 0.0457 - val_mse: 0.0108\n",
            "Epoch 391/500\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0435 - mse: 0.0093 - val_loss: 0.0437 - val_mse: 0.0101\n",
            "Epoch 392/500\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0426 - mse: 0.0088 - val_loss: 0.0417 - val_mse: 0.0092\n",
            "Epoch 393/500\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0400 - mse: 0.0079 - val_loss: 0.0399 - val_mse: 0.0086\n",
            "Epoch 394/500\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.0386 - mse: 0.0074 - val_loss: 0.0401 - val_mse: 0.0082\n",
            "Epoch 395/500\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0391 - mse: 0.0072 - val_loss: 0.0398 - val_mse: 0.0078\n",
            "Epoch 396/500\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.0378 - mse: 0.0067 - val_loss: 0.0420 - val_mse: 0.0076\n",
            "Epoch 397/500\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.0411 - mse: 0.0067 - val_loss: 0.0435 - val_mse: 0.0075\n",
            "Epoch 398/500\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 0.0413 - mse: 0.0065 - val_loss: 0.0400 - val_mse: 0.0069\n",
            "Epoch 399/500\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0391 - mse: 0.0062 - val_loss: 0.0363 - val_mse: 0.0057\n",
            "Epoch 400/500\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.0354 - mse: 0.0050 - val_loss: 0.0334 - val_mse: 0.0050\n",
            "Epoch 401/500\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.0331 - mse: 0.0044 - val_loss: 0.0324 - val_mse: 0.0046\n",
            "Epoch 402/500\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.0329 - mse: 0.0041 - val_loss: 0.0335 - val_mse: 0.0045\n",
            "Epoch 403/500\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.0329 - mse: 0.0040 - val_loss: 0.0367 - val_mse: 0.0049\n",
            "Epoch 404/500\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.0363 - mse: 0.0047 - val_loss: 0.0376 - val_mse: 0.0052\n",
            "Epoch 405/500\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 0.0363 - mse: 0.0047 - val_loss: 0.0339 - val_mse: 0.0041\n",
            "Epoch 406/500\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0341 - mse: 0.0040 - val_loss: 0.0311 - val_mse: 0.0037\n",
            "Epoch 407/500\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.0309 - mse: 0.0035 - val_loss: 0.0302 - val_mse: 0.0032\n",
            "Epoch 408/500\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.0310 - mse: 0.0033 - val_loss: 0.0274 - val_mse: 0.0027\n",
            "Epoch 409/500\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.0287 - mse: 0.0028 - val_loss: 0.0254 - val_mse: 0.0023\n",
            "Epoch 410/500\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.0270 - mse: 0.0025 - val_loss: 0.0263 - val_mse: 0.0024\n",
            "Epoch 411/500\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.0282 - mse: 0.0026 - val_loss: 0.0316 - val_mse: 0.0032\n",
            "Epoch 412/500\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.0324 - mse: 0.0034 - val_loss: 0.0339 - val_mse: 0.0036\n",
            "Epoch 413/500\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0351 - mse: 0.0040 - val_loss: 0.0290 - val_mse: 0.0027\n",
            "Epoch 414/500\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.0304 - mse: 0.0030 - val_loss: 0.0244 - val_mse: 0.0020\n",
            "Epoch 415/500\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 0.0272 - mse: 0.0025 - val_loss: 0.0234 - val_mse: 0.0019\n",
            "Epoch 416/500\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 0.0262 - mse: 0.0024 - val_loss: 0.0225 - val_mse: 0.0018\n",
            "Epoch 417/500\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.0259 - mse: 0.0024 - val_loss: 0.0281 - val_mse: 0.0026\n",
            "Epoch 418/500\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 0.0299 - mse: 0.0030 - val_loss: 0.0386 - val_mse: 0.0050\n",
            "Epoch 419/500\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.0404 - mse: 0.0057 - val_loss: 0.0257 - val_mse: 0.0020\n",
            "Epoch 420/500\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.0285 - mse: 0.0026 - val_loss: 0.0326 - val_mse: 0.0035\n",
            "Epoch 421/500\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.0342 - mse: 0.0039 - val_loss: 0.0381 - val_mse: 0.0046\n",
            "Epoch 422/500\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.0403 - mse: 0.0054 - val_loss: 0.0230 - val_mse: 0.0019\n",
            "Epoch 423/500\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.0263 - mse: 0.0024 - val_loss: 0.0367 - val_mse: 0.0049\n",
            "Epoch 424/500\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0379 - mse: 0.0052 - val_loss: 0.0326 - val_mse: 0.0037\n",
            "Epoch 425/500\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 0.0347 - mse: 0.0042 - val_loss: 0.0218 - val_mse: 0.0019\n",
            "Epoch 426/500\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.0250 - mse: 0.0024 - val_loss: 0.0270 - val_mse: 0.0027\n",
            "Epoch 427/500\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0288 - mse: 0.0031 - val_loss: 0.0371 - val_mse: 0.0048\n",
            "Epoch 428/500\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.0390 - mse: 0.0054 - val_loss: 0.0236 - val_mse: 0.0020\n",
            "Epoch 429/500\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.0273 - mse: 0.0025 - val_loss: 0.0398 - val_mse: 0.0061\n",
            "Epoch 430/500\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0413 - mse: 0.0063 - val_loss: 0.0275 - val_mse: 0.0026\n",
            "Epoch 431/500\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.0302 - mse: 0.0030 - val_loss: 0.0307 - val_mse: 0.0029\n",
            "Epoch 432/500\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.0331 - mse: 0.0033 - val_loss: 0.0403 - val_mse: 0.0047\n",
            "Epoch 433/500\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0409 - mse: 0.0049 - val_loss: 0.0304 - val_mse: 0.0028\n",
            "Epoch 434/500\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0327 - mse: 0.0032 - val_loss: 0.0285 - val_mse: 0.0029\n",
            "Epoch 435/500\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0307 - mse: 0.0033 - val_loss: 0.0429 - val_mse: 0.0058\n",
            "Epoch 436/500\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.0432 - mse: 0.0059 - val_loss: 0.0223 - val_mse: 0.0021\n",
            "Epoch 437/500\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0248 - mse: 0.0024 - val_loss: 0.0399 - val_mse: 0.0044\n",
            "Epoch 438/500\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0414 - mse: 0.0048 - val_loss: 0.0321 - val_mse: 0.0035\n",
            "Epoch 439/500\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0337 - mse: 0.0037 - val_loss: 0.0324 - val_mse: 0.0028\n",
            "Epoch 440/500\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0344 - mse: 0.0030 - val_loss: 0.0342 - val_mse: 0.0034\n",
            "Epoch 441/500\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0361 - mse: 0.0037 - val_loss: 0.0344 - val_mse: 0.0037\n",
            "Epoch 442/500\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0355 - mse: 0.0039 - val_loss: 0.0295 - val_mse: 0.0025\n",
            "Epoch 443/500\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.0317 - mse: 0.0028 - val_loss: 0.0349 - val_mse: 0.0038\n",
            "Epoch 444/500\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0365 - mse: 0.0043 - val_loss: 0.0290 - val_mse: 0.0025\n",
            "Epoch 445/500\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0309 - mse: 0.0028 - val_loss: 0.0293 - val_mse: 0.0026\n",
            "Epoch 446/500\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0316 - mse: 0.0029 - val_loss: 0.0326 - val_mse: 0.0032\n",
            "Epoch 447/500\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.0347 - mse: 0.0036 - val_loss: 0.0259 - val_mse: 0.0023\n",
            "Epoch 448/500\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.0275 - mse: 0.0025 - val_loss: 0.0271 - val_mse: 0.0022\n",
            "Epoch 449/500\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0294 - mse: 0.0025 - val_loss: 0.0261 - val_mse: 0.0026\n",
            "Epoch 450/500\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0281 - mse: 0.0029 - val_loss: 0.0287 - val_mse: 0.0026\n",
            "Epoch 451/500\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0303 - mse: 0.0028 - val_loss: 0.0256 - val_mse: 0.0023\n",
            "Epoch 452/500\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0283 - mse: 0.0026 - val_loss: 0.0245 - val_mse: 0.0021\n",
            "Epoch 453/500\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0266 - mse: 0.0023 - val_loss: 0.0279 - val_mse: 0.0025\n",
            "Epoch 454/500\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0293 - mse: 0.0027 - val_loss: 0.0289 - val_mse: 0.0028\n",
            "Epoch 455/500\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0307 - mse: 0.0031 - val_loss: 0.0260 - val_mse: 0.0024\n",
            "Epoch 456/500\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0274 - mse: 0.0026 - val_loss: 0.0230 - val_mse: 0.0019\n",
            "Epoch 457/500\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.0253 - mse: 0.0022 - val_loss: 0.0238 - val_mse: 0.0022\n",
            "Epoch 458/500\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0261 - mse: 0.0025 - val_loss: 0.0283 - val_mse: 0.0028\n",
            "Epoch 459/500\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0293 - mse: 0.0030 - val_loss: 0.0235 - val_mse: 0.0023\n",
            "Epoch 460/500\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.0258 - mse: 0.0026 - val_loss: 0.0227 - val_mse: 0.0020\n",
            "Epoch 461/500\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 0.0246 - mse: 0.0023 - val_loss: 0.0218 - val_mse: 0.0020\n",
            "Epoch 462/500\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.0238 - mse: 0.0022 - val_loss: 0.0251 - val_mse: 0.0025\n",
            "Epoch 463/500\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0270 - mse: 0.0028 - val_loss: 0.0261 - val_mse: 0.0028\n",
            "Epoch 464/500\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0271 - mse: 0.0030 - val_loss: 0.0240 - val_mse: 0.0023\n",
            "Epoch 465/500\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.0259 - mse: 0.0025 - val_loss: 0.0241 - val_mse: 0.0024\n",
            "Epoch 466/500\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0257 - mse: 0.0026 - val_loss: 0.0241 - val_mse: 0.0024\n",
            "Epoch 467/500\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0261 - mse: 0.0027 - val_loss: 0.0215 - val_mse: 0.0020\n",
            "Epoch 468/500\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0234 - mse: 0.0021 - val_loss: 0.0199 - val_mse: 0.0019\n",
            "Epoch 469/500\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0222 - mse: 0.0021 - val_loss: 0.0201 - val_mse: 0.0019\n",
            "Epoch 470/500\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.0223 - mse: 0.0021 - val_loss: 0.0193 - val_mse: 0.0019\n",
            "Epoch 471/500\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0216 - mse: 0.0021 - val_loss: 0.0217 - val_mse: 0.0020\n",
            "Epoch 472/500\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0235 - mse: 0.0022 - val_loss: 0.0221 - val_mse: 0.0023\n",
            "Epoch 473/500\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.0240 - mse: 0.0025 - val_loss: 0.0241 - val_mse: 0.0024\n",
            "Epoch 474/500\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0256 - mse: 0.0026 - val_loss: 0.0246 - val_mse: 0.0025\n",
            "Epoch 475/500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0267 - mse: 0.0028 - val_loss: 0.0209 - val_mse: 0.0020\n",
            "Epoch 476/500\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.0230 - mse: 0.0022 - val_loss: 0.0205 - val_mse: 0.0019\n",
            "Epoch 477/500\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0229 - mse: 0.0021 - val_loss: 0.0238 - val_mse: 0.0023\n",
            "Epoch 478/500\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0258 - mse: 0.0026 - val_loss: 0.0260 - val_mse: 0.0025\n",
            "Epoch 479/500\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0274 - mse: 0.0027 - val_loss: 0.0264 - val_mse: 0.0026\n",
            "Epoch 480/500\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0281 - mse: 0.0029 - val_loss: 0.0246 - val_mse: 0.0024\n",
            "Epoch 481/500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0259 - mse: 0.0025 - val_loss: 0.0225 - val_mse: 0.0020\n",
            "Epoch 482/500\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.0252 - mse: 0.0023 - val_loss: 0.0204 - val_mse: 0.0018\n",
            "Epoch 483/500\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0230 - mse: 0.0021 - val_loss: 0.0231 - val_mse: 0.0021\n",
            "Epoch 484/500\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0253 - mse: 0.0023 - val_loss: 0.0237 - val_mse: 0.0024\n",
            "Epoch 485/500\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0257 - mse: 0.0026 - val_loss: 0.0303 - val_mse: 0.0029\n",
            "Epoch 486/500\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0312 - mse: 0.0030 - val_loss: 0.0281 - val_mse: 0.0028\n",
            "Epoch 487/500\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0293 - mse: 0.0031 - val_loss: 0.0231 - val_mse: 0.0021\n",
            "Epoch 488/500\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.0251 - mse: 0.0023 - val_loss: 0.0225 - val_mse: 0.0020\n",
            "Epoch 489/500\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0248 - mse: 0.0022 - val_loss: 0.0260 - val_mse: 0.0025\n",
            "Epoch 490/500\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0282 - mse: 0.0028 - val_loss: 0.0253 - val_mse: 0.0025\n",
            "Epoch 491/500\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0269 - mse: 0.0027 - val_loss: 0.0251 - val_mse: 0.0022\n",
            "Epoch 492/500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0272 - mse: 0.0025 - val_loss: 0.0219 - val_mse: 0.0020\n",
            "Epoch 493/500\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.0243 - mse: 0.0022 - val_loss: 0.0215 - val_mse: 0.0020\n",
            "Epoch 494/500\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0236 - mse: 0.0022 - val_loss: 0.0285 - val_mse: 0.0029\n",
            "Epoch 495/500\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.0300 - mse: 0.0032 - val_loss: 0.0275 - val_mse: 0.0025\n",
            "Epoch 496/500\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0289 - mse: 0.0027 - val_loss: 0.0229 - val_mse: 0.0020\n",
            "Epoch 497/500\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0251 - mse: 0.0022 - val_loss: 0.0238 - val_mse: 0.0021\n",
            "Epoch 498/500\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0254 - mse: 0.0022 - val_loss: 0.0203 - val_mse: 0.0018\n",
            "Epoch 499/500\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0227 - mse: 0.0020 - val_loss: 0.0213 - val_mse: 0.0019\n",
            "Epoch 500/500\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.0238 - mse: 0.0021 - val_loss: 0.0213 - val_mse: 0.0019\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0231 - mse: 0.0019\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f0996243ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 486ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Validation loss: [0.023092882707715034, 0.0018598355818539858]\n",
            "['loss', 'mse']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1iff8O7OcATl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "# Define the input and output sequences\n",
        "input_seq = np.random.randn(100, 10, 1) # shape: (num_samples, sequence_length, input_dim)\n",
        "output_seq = np.random.randn(100, 5, 1) # shape: (num_samples, output_sequence_length, output_dim)\n",
        "\n",
        "# Define the LSTM model\n",
        "model = Sequential()\n",
        "#model.add(LSTM(64, input_shape=(10, 1))) # 64 is the number of hidden units in the LSTM layer\n",
        "#model.add(Dense(5)) # 5 is the output sequence length\n",
        "model.add(LSTM(64, input_shape=(4, 24))) # 64 is the number of hidden units in the LSTM layer\n",
        "model.add(Dense(4)) # 5 is the output sequence length\n",
        "model.compile(loss='mse', optimizer='adam')\n",
        "\n",
        "#padded_Ecodes = padded_EcodesP.reshape(42, 4, 24, 1)\n",
        "#padded_Pcodes = padded_Pcodes.reshape(42, 4, 24, 1)\n",
        "\n",
        "\n",
        "# Train the model\n",
        "#model.fit(input_seq, output_seq, epochs=50, batch_size=32)\n",
        "model.fit(padded_Ecodes, padded_Pcodes, epochs=50)\n",
        "\n",
        "# Generate predictions on new data\n",
        "new_data = np.random.randn(1, 10, 1) # shape: (num_samples, sequence_length, input_dim)\n",
        "preds = model.predict(new_data) # shape: (num_samples, output_sequence_length, output_dim)"
      ],
      "metadata": {
        "id": "9l7Kl_D-bpeC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}